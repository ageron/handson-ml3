{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "# RO47002 Machine Learning for Robotics\n",
    "* (c) TU Delft, 2024\n",
    "* Period: 2024-2025, Q1\n",
    "* Course homepage: https://brightspace.tudelft.nl/d2l/home/682421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Make sure you fill in any place that says `YOUR CODE HERE` or `YOUR ANSWER HERE`. Moreover, if you see an empty cell, please DO NOT delete it, instead run that cell as you would run all other cells. Please fill in your name(s) and other required details below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "GROUP_NUMBER = \"23\"\n",
    "STUDENT_NAME1 = \"Daniel Rugge\"\n",
    "STUDENT_NUMBER1 = \"x\"\n",
    "STUDENT_NAME2 = \"Daan Bouwmeester\"\n",
    "STUDENT_NUMBER2 = \"5146143\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e3f76d6a626db81c484191482b101edb",
     "grade": true,
     "grade_id": "cell-c35e4c8223095209",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Note: this block is a check that you have filled in the above information.\n",
    "# It will throw an AssertionError until all fields are filled\n",
    "assert(GROUP_NUMBER != \"\")\n",
    "assert(STUDENT_NAME1 != \"\")\n",
    "assert(STUDENT_NUMBER1 != \"\")\n",
    "assert(STUDENT_NAME2 != \"\")\n",
    "assert(STUDENT_NUMBER2 != \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### General announcements\n",
    "\n",
    "* Do *not* share your solutions, and do *not* copy solutions from others. By submitting your solutions, you claim that you and your lab partner alone are responsible for this code.\n",
    "\n",
    "* Do *not* email questions directly, since we want to provide everybody with the same information and avoid repeating the same answers. Instead, please post your questions regarding this assignment in the correct support forum on Brightspace, this way everybody can benefit from the response. If you do have a particular question that you want to ask directly, please use the scheduled practicum hours to ask a TA.\n",
    "\n",
    "* There is a strict deadline for each assignment. Students are responsible to ensure that they have uploaded their work in time. So, please double check that your upload succeeded to the Brightspace and avoid any late penalties.\n",
    "\n",
    "* This [Jupyter notebook](https://jupyter.org/) uses `nbgrader` to help us with automated tests. `nbgrader` will make various cells in this notebook \"uneditable\" or \"unremovable\" and gives them a special id in the cell metadata. This way, when we run our checks, the system will check the existence of the cell ids and verify the number of points and which checks must be run. While there are ways that you can edit the metadata and work around the restrictions to delete or modify these special cells, you should not do that since then our nbgrader backend will not be able to parse your notebook and give you points for the assignment. You are free to add additional cells, but if you find a cell that you cannot modify or remove, please know that this is on purpose.\n",
    "\n",
    "* This notebook will have in various places a line that throws a `NotImplementedError` exception. These are locations where the assignment requires you to adapt the code! These lines are just there as a reminder for youthat you have not yet adapted that particular piece of code, especially when you execute all the cells. Once your solution code replaced these lines, it should accordingly *not* throw any exceptions anymore.\n",
    "\n",
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "110f0131770c2c745a205927dacb7d1d",
     "grade": false,
     "grade_id": "cell-82c5841231ad1b4b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Practicum 4\n",
    "\n",
    "* Topic:  SVMs, Decision trees, Ensemble Methods, imitation learning\n",
    "* Before performing this practicum, work through **Book chapter(s): 5, 6, 7**\n",
    "* **Deadline**: Monday, September 30, 2024, 23:59\n",
    "\n",
    "## Objectives\n",
    "\n",
    "### Part 1 - SVMs, Decision trees, Ensemble methods\n",
    "* Discover a data set and prepare it for algorithms\n",
    "* Use SKLearn libraries to implement classifiers\n",
    "* Inspect a decision tree\n",
    "* Explore how bagging improves a very simple classifier\n",
    "\n",
    "### Part 2 - Implementations\n",
    "* Re-implement a linear SVM\n",
    "* Re-implement a voting classifier\n",
    "\n",
    "### Part 3 - Imitation Learning and Motion Planning\n",
    "* Build a dataset using an oracle\n",
    "* Use a classifier to imitate the behavior of a motion planning algorithm\n",
    "* Explore how the construction of the dataset can affect the performance of the classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "### Setup common python stuff\n",
    "We will start by loading a few common python dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f5eb9db5322c7c4c306943b10cbdf8f7",
     "grade": false,
     "grade_id": "cell-9774d5992524490c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Python =3.10 is required\n",
    "import sys\n",
    "assert sys.version_info[:2] == (3, 10)\n",
    "\n",
    "# Scikit-Learn 1.1 is required\n",
    "import sklearn\n",
    "assert (sklearn.__version__ >= \"1.1\" and sklearn.__version__ <= \"1.3.2\")\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "399d593fa180c278904953d8f425795d",
     "grade": false,
     "grade_id": "cell-01840b9338f29b7a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_feature_space_function(f, X, y, axes, class_1=0, class_2=1, res=0.1):\n",
    "    \"\"\" \n",
    "    Plot the 2D feature space of the first two features of the data in X.\n",
    "    For the feature space, plot the samples in X with their class labels y,\n",
    "    and also overlay a countour plot with the function f(x) evaluated at a grid within\n",
    "    the shown region of the feature space (the size of the region is determined by the extent of the data).\n",
    "    based on https://scikit-learn.org/stable/auto_examples/ensemble/plot_voting_decision_regions.html\n",
    "    \"\"\"\n",
    "    \n",
    "    if f is not None:\n",
    "        xx, yy = np.meshgrid(np.arange(axes[0], axes[1], res),np.arange(axes[2], axes[3], res))\n",
    "\n",
    "        Z = f(np.c_[xx.ravel(), yy.ravel()])\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "        \n",
    "    plt.plot(X[y==class_1,0], X[y==class_1,1], '.', label='class '+str(class_1), zorder=-1)\n",
    "    plt.plot(X[y==class_2,0], X[y==class_2,1], '.', label='class '+str(class_2), zorder=-1)\n",
    "    plt.grid('on')\n",
    "    plt.axis(axes)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b361db71923bb42f75004f7172250ac8",
     "grade": false,
     "grade_id": "cell-944064faeae1cccf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def print_accuracy_confusion(y_test, y_pred, clf_name=''):\n",
    "    print(clf_name, 'accuracy score:', accuracy_score(y_test, y_pred))\n",
    "    print(clf_name, 'confusion matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "05ea6e549c5735277c17578ea70b8fab",
     "grade": false,
     "grade_id": "cell-2683ae0bcb36f052",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1) Exploring and preparing a dataset\n",
    "We are going to use a dataset for classifying hand gestures from EMG signals for the first part of this practicum. The description and original source can be found here: https://www.kaggle.com/kyr7plus/emg-4\n",
    "\n",
    "This kind of data cannot only be used for controlling prosthetics, but also for other human-robot interaction applications. Here is a little example from another CoR staff member, Luka Peternel, on the use of EMG sensors in human-robot interaction https://youtu.be/eXspt7_KY8c?t=156\n",
    "\n",
    "Your first task is to read the description on the website and to figure out how the dataset is structured.\n",
    "Load the correct file (included in folder `hand_gestures` in this practicum) for each variable `df_rock`, `df_paper`, `df_scissors`, and `df_ok` using "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0f109d6aeb9d665c6ffeb28ba55229f7",
     "grade": false,
     "grade_id": "cell-d760dcadce68aa37",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/hand_gestures/1.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m df_rock \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./hand_gestures/0.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 2\u001b[0m df_paper \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/hand_gestures/1.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df_scissors \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/hand_gestures/2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m df_ok \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/hand_gestures/3.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, header \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\daanb\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\daanb\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\daanb\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\daanb\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1706\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1707\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1708\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1709\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1710\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1711\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1712\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1713\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1714\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\daanb\\anaconda3\\envs\\homl3\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    864\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    865\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/hand_gestures/1.csv'"
     ]
    }
   ],
   "source": [
    "df_rock = pd.read_csv('./hand_gestures/0.csv', header = None)\n",
    "df_paper = pd.read_csv('/hand_gestures/1.csv', header = None)\n",
    "df_scissors = pd.read_csv('/hand_gestures/2.csv', header = None)\n",
    "df_ok = pd.read_csv('/hand_gestures/3.csv', header = None)\n",
    "\n",
    "df = pd.concat([df_rock, df_scissors, df_ok,  df_paper])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d19970c75088dc4ac404eeb91891be0b",
     "grade": true,
     "grade_id": "cell-5480d57b76e0b093",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert df.shape[0] == 11678\n",
    "assert df.shape[1] == 65"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9ff6dc52ca69d91f559a9e58b102fc72",
     "grade": false,
     "grade_id": "cell-290b43b8856ab809",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.01)** Now convert the pandas dataframe to numpy matrices `X_4class` and `y_4class` for the features and labels respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a7dec4d4446867e52d3d576b9bf74c8",
     "grade": false,
     "grade_id": "cell-a3bccf04386cbe19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hint: use df.iloc.values or np.array(df)\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "41cbf1e6d689004a43caca1216885297",
     "grade": true,
     "grade_id": "cell-e0a8b998769c2ceb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_4class.shape[0] == 11678\n",
    "assert y_4class.shape[0] == 11678\n",
    "assert y_4class.ndim == 1\n",
    "assert isinstance(X_4class, np.ndarray)\n",
    "assert isinstance(y_4class, np.ndarray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#if you are stuck here, uncomment the lines below to load variables\n",
    "\n",
    "# npzfile = np.load('./get_unstuck/4class.npz')\n",
    "# X_4class = npzfile['X_4class']\n",
    "# y_4class = npzfile['y_4class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9203d241e86c17dc989ee9f1f29aba2a",
     "grade": false,
     "grade_id": "cell-7c5611bacaa4778f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>ðŸŽ¥ <a href=\"https://brightspace.tudelft.nl/d2l/le/content/682421/viewContent/3726377/View\">Lecture 4A - SVMs (intuition)</a></h3>\n",
    "    <h3>ðŸŽ¥ <a href=\"https://brightspace.tudelft.nl/d2l/le/content/682421/viewContent/3726379/View\">Lecture 4B - SVMs (formalized)</a></h3>\n",
    "    <h3>ðŸŽ¥ <a href=\"https://brightspace.tudelft.nl/d2l/le/content/682421/viewContent/3726381/View\">Lecture 4C - SVMs (hyperparameter C)</a></h3>\n",
    "    <h3>ðŸŽ¥ <a href=\"https://brightspace.tudelft.nl/d2l/le/content/682421/viewContent/3726425/View\">Lecture 4E - Decision Trees</a></h3>\n",
    "    <h3>ðŸŽ¥ <a href=\"https://brightspace.tudelft.nl/d2l/le/content/682421/viewContent/3726427/View\">Lecture 4F - Ensemble Methods</a></h3>\n",
    "    The following requires the knowledge covered in this lecture. If you haven't watched the video yet, it's now high time to do so...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "40fdecf934c63c5b8f05bc2af03663fe",
     "grade": false,
     "grade_id": "cell-7e0baaa30dfaa972",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.02)** Let's use classifiers in the SKLearn library to create an SGD, a SVM, a DT, and a RF with the following parameters:\n",
    "- `random_state=0`\n",
    "- SGD should use the log loss.\n",
    "- The SVM must have HARD margings, set the parameter `svm_C` accordingly.\n",
    "- The DT must have at maximum 3 levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0dab141344c259276f537c644abd4d1b",
     "grade": false,
     "grade_id": "cell-584f9bce4ccb27b7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_4class_train, X_4class_test, y_4class_train, y_4class_test = train_test_split(X_4class, y_4class, test_size=0.25, random_state=0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_4class = StandardScaler()\n",
    "X_4class_train = sc_4class.fit_transform(X_4class_train)\n",
    "X_4class_test = sc_4class.transform(X_4class_test)\n",
    "\n",
    "# Define the classifiers parameters\n",
    "random_state = None\n",
    "sgd_loss = None\n",
    "svm_C = None\n",
    "dt_max_depth = None\n",
    "\n",
    "# Defining and fitting classifier\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "sgd_clf_4class.fit(X_4class_train, y_4class_train)\n",
    "svm_clf_4class.fit(X_4class_train, y_4class_train)\n",
    "dt_clf_4class.fit(X_4class_train, y_4class_train)\n",
    "rf_clf_4class.fit(X_4class_train, y_4class_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "sgd_y_4class_pred = sgd_clf_4class.predict(X_4class_test)\n",
    "svm_y_4class_pred = svm_clf_4class.predict(X_4class_test)\n",
    "dt_y_4class_pred = dt_clf_4class.predict(X_4class_test)\n",
    "rf_y_4class_pred = rf_clf_4class.predict(X_4class_test)\n",
    "\n",
    "print_accuracy_confusion(y_4class_test, sgd_y_4class_pred)\n",
    "print_accuracy_confusion(y_4class_test, svm_y_4class_pred)\n",
    "print_accuracy_confusion(y_4class_test, dt_y_4class_pred)\n",
    "print_accuracy_confusion(y_4class_test, rf_y_4class_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "acd410583b0e31233adc0f2e7a9c9f6e",
     "grade": true,
     "grade_id": "cell-d800153ad4a39d38",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please note: The expected outcome for the worst classifier should be better than 30%, and the others will perform even better.\n",
    "assert accuracy_score(y_4class_test, sgd_y_4class_pred) > 0.3\n",
    "assert accuracy_score(y_4class_test, svm_y_4class_pred) > 0.3\n",
    "assert accuracy_score(y_4class_test, dt_y_4class_pred) > 0.3\n",
    "assert accuracy_score(y_4class_test, rf_y_4class_pred) > 0.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "864f6110b6bc60206da704d1d78aea04",
     "grade": false,
     "grade_id": "cell-eca889c693072167",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.03)** You might have noticed that both SGD and DT have a poor accuracy score. Instead of tuning the hyper-parameters, we will work the data to show its influence on the methods.\n",
    "\n",
    "For that, we will consider only 2 out of the 4 classes in this dataset which are easiest to distinguish, so we can focus on binary classifiers.\n",
    "Based on the confusion matrix above, which classes are easiest to distinguish?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c0f6754e4293377fa42a8b244b3ed6b9",
     "grade": false,
     "grade_id": "cell-9267048a15e40452",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Set the correct value. Ensure that feat_1 < feat_2.\n",
    "class_1 = None\n",
    "class_2 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59fb6447bb0ed950346a0d4ee55e0ff5",
     "grade": true,
     "grade_id": "cell-90b8878c597a79a5",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert class_1 is not None\n",
    "assert class_2 is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "497bb34c4eb6a88b2171c1030336ba25",
     "grade": false,
     "grade_id": "cell-3a319305ea30ed04",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.04)** Now we create 2 new variables `X_binary` and `y_binary` that only contain these 2 classes (the easiest to distinguish). Hint: use Boolean indexing and bitwise logic operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4edfa5164f0a1ef2ac67455a2082cd10",
     "grade": false,
     "grade_id": "cell-bd1bbca0a7d4b6ad",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f95751d67e13255563a676cd09e957b4",
     "grade": true,
     "grade_id": "cell-417e34dd424b7b85",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_binary.shape[0] == 5813\n",
    "assert X_binary.shape[1] == 64\n",
    "assert y_binary.ndim == 1\n",
    "assert X_binary[0,0] == 26.0\n",
    "assert X_binary[5812,0] == -16.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#If you are stuck here, uncomment the lines below to load variables\n",
    "\n",
    "#npzfile = np.load('./get_unstuck/binary.npz')\n",
    "#X_binary = npzfile['X_binary']\n",
    "#y_binary = npzfile['y_binary']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "57bdbb5a311a1f910b51f25b6ed7936a",
     "grade": false,
     "grade_id": "cell-c60a28cfb2263a09",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Preparing the modified dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c39b75dab6f45801666108ac196e781d",
     "grade": false,
     "grade_id": "cell-d89b61294c92317b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_binary_train, X_binary_test, y_binary_train, y_binary_test = train_test_split(X_binary, y_binary, test_size=0.25, random_state=0)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_binary = StandardScaler()\n",
    "X_binary_train = sc_binary.fit_transform(X_binary_train)\n",
    "X_binary_test = sc_binary.transform(X_binary_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**1.05)** Now let's create classifiers to see how they perform on the new data (the parameters not defined here must be set to default).\n",
    "- `random_state = 0`\n",
    "- a SVM classifier `svm_clf_binary`, with `C=100`\n",
    "- a SGD classifier `sgd_clf_binary`, with log loss\n",
    "- a decision tree classifier `dt_clf_binary`\n",
    "- a random forest classifier `rf_clf_binary`\n",
    "\n",
    "define them, fit them, and predict the values for the test set (use the variable names in the stub that displays the results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07ee995caa6ad1d9868e73252c2406ed",
     "grade": false,
     "grade_id": "cell-5a02ba5a8f8ffeaf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Defining and fitting mutliple classifiers\n",
    "\n",
    "# Predicting the Test set results\n",
    "# ATTENTION: Remove these values and make sure to attribute the correct predictions\n",
    "sgd_y_binary_pred = np.zeros(len(X_binary_test))\n",
    "svm_y_binary_pred = np.zeros(len(X_binary_test))\n",
    "dt_y_binary_pred = np.zeros(len(X_binary_test))\n",
    "rf_y_binary_pred = np.zeros(len(X_binary_test))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Printing results\n",
    "print_accuracy_confusion(y_binary_test, sgd_y_binary_pred, 'sgd')\n",
    "print_accuracy_confusion(y_binary_test, svm_y_binary_pred, 'svm')\n",
    "print_accuracy_confusion(y_binary_test, dt_y_binary_pred, 'dt')\n",
    "print_accuracy_confusion(y_binary_test, rf_y_binary_pred, 'rf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60204d8206e20a21df4a319bd07f0674",
     "grade": true,
     "grade_id": "cell-ac4d9730cd150c2e",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please note: The expected outcome for the worst classifier should be better than 50%, and the others will perform even better.\n",
    "assert accuracy_score(y_binary_test, sgd_y_binary_pred) > 0.5\n",
    "assert accuracy_score(y_binary_test, svm_y_binary_pred) > 0.5\n",
    "assert accuracy_score(y_binary_test, dt_y_binary_pred) > 0.5\n",
    "assert accuracy_score(y_binary_test, rf_y_binary_pred) > 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e714e4ce7ae19cb764646e34395f78b8",
     "grade": false,
     "grade_id": "cell-a575294442eba47e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Note how the accuracy score of the DT has increased. Remember from the class, DTs are strongly impacted by the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab61db1b1b1ee262983ac754985f7175",
     "grade": false,
     "grade_id": "cell-9c698b3269011801",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.06)** The dataset has 64 features, which are virtually impossible to visualize in 2D. The next steps are going to take us from those 64 features down to 2 features.\n",
    "\n",
    "Take a look again at the description of the data set. Each sample contains measurements from 8 sensors, over 8 consecutive time steps. The measurements are very noisy anyhow, so average over the 8 time steps and create a new variable `X_binary_avg`. That can be done in 2 lines with numpy functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1f47c348a343f03b0904cbeb142c78eb",
     "grade": false,
     "grade_id": "cell-6f84b4e8d72dc0ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06b92dbf0d4e3e7fcfff100fe344955c",
     "grade": true,
     "grade_id": "cell-c3036fe1dc2b6a34",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_binary_avg.shape[0] == 5813\n",
    "assert X_binary_avg.shape[1] == 8\n",
    "assert X_binary_avg[0,0] == 8\n",
    "assert X_binary_avg[5812,0] == 1.375"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#if you are stuck here, uncomment the lines below to load variables\n",
    "\n",
    "# npzfile = np.load('./get_unstuck/binary_avg.npz')\n",
    "# X_binary_avg= npzfile['X_binary_avg']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5643f44605016bc20fa28c4c7dac6b9a",
     "grade": false,
     "grade_id": "cell-56be2594481a72be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.07)** Explore manually the dataset to see which features clearly distinguish the 2 classes (although it is not be possible to completely eliminate the overlap between classes). The function below can help with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49d0081a883e11efdc3efd849a8e65fc",
     "grade": false,
     "grade_id": "cell-d6c77c8af4ce919c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_data(X, y, feat_1, feat_2, class_1=0, class_2=1):\n",
    "    plt.plot(X[y==class_1,feat_1], X[y==class_1,feat_2], '.', label='class '+str(class_1))\n",
    "    plt.plot(X[y==class_2,feat_1], X[y==class_2,feat_2], '.', label='class '+str(class_2))\n",
    "    plt.grid('on')\n",
    "    plt.axis('equal')\n",
    "    plt.xlabel('feature ' + str(feat_1))\n",
    "    plt.ylabel('feature ' + str(feat_2))\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# an empty cell for your own code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e971b860f263d6c0b1e1a1a18b9397fb",
     "grade": false,
     "grade_id": "cell-a85d7de8873536d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Add the correct values here. Ensure that feat_1 < feat_2.\n",
    "feat_1 = None\n",
    "feat_2 = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "plot_data(X_binary_avg, y_binary, feat_1, feat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "64ec4b86ddb3055093d7fb1e9138c0bd",
     "grade": true,
     "grade_id": "cell-6ca7aa733bf6eb5c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert feat_1 is not None\n",
    "assert feat_2 is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "**1.08)** Instead of checking the feature spaces manually (which is not always possible), we can also use an auto-generated decision tree to help us decide on the most informative features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a23d88d2f026bd0648145b680d3dfad6",
     "grade": false,
     "grade_id": "cell-5982ab5b77789271",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_simple_train, X_simple_test, y_simple_train, y_simple_test = train_test_split(X_binary_avg, y_binary, test_size=0.25, random_state=0)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf_simple = DecisionTreeClassifier(random_state=0, max_depth=3)\n",
    "dt_clf_simple.fit(X_simple_train, y_simple_train)\n",
    "dt_y_simple_pred = dt_clf_simple.predict(X_simple_test)\n",
    "\n",
    "print_accuracy_confusion(y_simple_test, dt_y_simple_pred, 'dt_simple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "508c43685145238a9175338ea3541aa2",
     "grade": false,
     "grade_id": "cell-1965177da9e27e0a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import graphviz \n",
    "dot_data = tree.export_graphviz(dt_clf_simple, out_file=None, filled=True, rounded=True, class_names=['0', '1'])  \n",
    "graph = graphviz.Source(dot_data) \n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8de6d9d01e791326f701de0697902970",
     "grade": false,
     "grade_id": "cell-3273989405b4ba1b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Hopefully you'll come to a similar conclusion than with manual inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3101268a790ab7e23d0d6e03ed3df3e7",
     "grade": false,
     "grade_id": "cell-97fc4c0d0ac0c06c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Add the correct values here. Ensure that feat_1 < feat_2.\n",
    "feat_1 = None\n",
    "feat_2 = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "10d94bf3d5f345eb01c1c04b58d1144c",
     "grade": true,
     "grade_id": "cell-7ab1d153fa98eb3d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert feat_1 is not None\n",
    "assert feat_2 is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe7b8bb9c5d05bb90d12bf0fac369753",
     "grade": false,
     "grade_id": "cell-7bff6afb2c3b922a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.09)** One of the features is clearly dominant. Which other feature to use is a bit less clear cut. In any case, to select the other one, use the one with the lower feature index. We are next going to look at SVMs. Those work best with small to medium data sets.\n",
    "\n",
    "Create a new subset of the averaged data (`X_binary_subset` and `y_binary_subset`) containing only the 2 features you chose and only every 3rd sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "df6d8dd8937fd43dd774b3c5f1706881",
     "grade": false,
     "grade_id": "cell-a6be45f64a76f37a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "be4d74f2ccc5a72b8c27daff0fdc7f8e",
     "grade": true,
     "grade_id": "cell-53c8681590e84abb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert X_binary_subset.shape[0] == 1938\n",
    "assert y_binary_subset.shape[0] == 1938\n",
    "assert X_binary_subset.shape[1] == 2\n",
    "assert X_binary_subset[0,0] == 0.5\n",
    "assert X_binary_subset[1937,0] == -0.375\n",
    "assert y_binary_subset[1937] == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#if you are stuck here, uncomment the lines below to load variables\n",
    "\n",
    "# npzfile = np.load('./get_unstuck/binary_subset.npz')\n",
    "# X_binary_subset = npzfile['X_binary_subset']\n",
    "# y_binary_subset = npzfile['y_binary_subset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "233acd28741088c360e15f20e4cc5957",
     "grade": false,
     "grade_id": "cell-dfafa226001ccddf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Again some setup of the data etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "363f4f85c9d5a490b7041aa2ccb4001f",
     "grade": false,
     "grade_id": "cell-9c07530ece09be9d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_subset_train, X_subset_test, y_subset_train, y_subset_test = train_test_split(X_binary_subset, y_binary_subset, test_size=0.25, random_state=0)\n",
    "\n",
    "axes_subset = np.array([X_binary_subset[:, 0].min() - 1, X_binary_subset[:, 0].max() + 1, X_binary_subset[:, 1].min() - 1, X_binary_subset[:, 1].max() + 1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "855210e7533955528bbe57b95c0c89b7",
     "grade": false,
     "grade_id": "cell-c9cbb9b65ecddb46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.10)** Here is a random forest classifier to see how well we can still perform on this very reduced dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2a6428524fc904c0e4e5d47a58d037d",
     "grade": false,
     "grade_id": "cell-6101f91405275b03",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Defining and fitting mutliple classifiers\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_clf_subset = RandomForestClassifier(random_state=0)\n",
    "rf_clf_subset.fit(X_subset_train, y_subset_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "rf_y_subset_pred = rf_clf_subset.predict(X_subset_test)\n",
    "\n",
    "print_accuracy_confusion(y_subset_test, rf_y_subset_pred, 'rf')\n",
    "plot_feature_space_function(rf_clf_subset.predict, X_binary_subset, y_binary_subset, axes_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d2fe2fce28b24bcdba2c1013b7dfdb33",
     "grade": false,
     "grade_id": "cell-6b3d2a4fa4325887",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**1.11)** We can still do surprisingly well compared to the full dataset, even though we have drastically reduced the number of features.\n",
    "\n",
    "Now create an non-linear SVM classifier `svm_clf_subset` that beats the random forest classifier in terms of accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "13ebfd8fc866c7a522686b363ba53a2e",
     "grade": false,
     "grade_id": "cell-2304532fe44da893",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print_accuracy_confusion(y_subset_test, svm_y_subset_pred, 'svm')\n",
    "plot_feature_space_function(svm_clf_subset.predict, X_binary_subset, y_binary_subset, axes_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f067905961bc48eaf7bef865e833b57",
     "grade": true,
     "grade_id": "cell-f43734c0b6ac2fba",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert accuracy_score(y_subset_test, svm_y_subset_pred) > 0.90103"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d3f8b205b99074d1d9bed237c6b9a08a",
     "grade": false,
     "grade_id": "cell-fd05925323ea4770",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# 2) Implementations\n",
    "\n",
    "In this part, we are going to implement a linear SVM using the dual formulation. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8bc0a14ff972811ee6a1711b76c6f188",
     "grade": false,
     "grade_id": "cell-ec5e08488b4515ab",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.1) SVM\n",
    "We will train the `sklearn` version of an SVM first, so we know what to expect from our own implementation. Check the Dual Formulation section in the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3>ðŸŽ¥ <a href=\"https://brightspace.tudelft.nl/d2l/le/content/682421/viewContent/3726423/View\">Lecture 4D - SVMs - Dual problem and Kernel Trick</a></h3>\n",
    "    The following part requires the knowledge covered in this lecture. If you haven't watched the video yet, it's now high time to do so...\n",
    "</div>\n",
    "\n",
    "**TIP:** being familiar with numpy arrays (see practicum 1) is also useful in this part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5cdf19956006200f2e6fee92fb069b68",
     "grade": false,
     "grade_id": "cell-aacb6d069dcae8a0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "As the data above can clearly not be separated by a linear decision boundary, we'll transform it once more. This obviously does not remove the overlap of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6837bea3ab9753f02488bf811f0a64ae",
     "grade": false,
     "grade_id": "cell-3892615979f61539",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_lin = np.abs(X_binary_subset)\n",
    "\n",
    "plot_data(np.abs(X_lin), y_binary_subset, 0, 1, 0, 1)\n",
    "plt.title('Absolute value')\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_lin, y_binary_subset, test_size = 0.25, random_state = 0)\n",
    "\n",
    "axes = np.array([X_lin[:, 0].min() - 1, X_lin[:, 0].max() + 1, X_lin[:, 1].min() - 1, X_lin[:, 1].max() + 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ede5d2196cdf9736c4143865cea582ef",
     "grade": false,
     "grade_id": "cell-28cffd0caba7b9c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.01)** Before testing SVMs, let's see how well linear classifiers do now..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e78dbbb5a6e4a848c17841408c5a0783",
     "grade": false,
     "grade_id": "cell-53a17ab3c2f57d34",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "sgd_clf = SGDClassifier(random_state=0)\n",
    "sgd_clf.fit(X_train, y_train);\n",
    "sgd_y_pred = sgd_clf.predict(X_test)\n",
    "print_accuracy_confusion(y_test, sgd_y_pred, 'sgd')\n",
    "plot_feature_space_function(sgd_clf.predict, X_lin, y_binary_subset, axes, 0 ,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "904d3f93c1800410e3bec4952d8c322e",
     "grade": false,
     "grade_id": "cell-eab3cadb2c452ba9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Actually a lot better than on the initial dataset...\n",
    "\n",
    "**2.1.02)** Now, before implementing an SVM, let's test with an sklearn linear SVM (using a linear kernel achieves the same as using LinearSVC, but this way of doing it gives us access to the support vectors). We'll compare our own implementation to this one later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2fd15d375df57b43f947a842507b1cb0",
     "grade": false,
     "grade_id": "cell-17f604f7187ba43b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "lin_svm_clf = SVC(kernel=\"linear\", C=2)\n",
    "lin_svm_clf.fit(X_train, y_train)\n",
    "lin_svm_y_pred = lin_svm_clf.predict(X_test)\n",
    "\n",
    "print_accuracy_confusion(y_test, lin_svm_y_pred, 'lin_svm')\n",
    "plot_feature_space_function(lin_svm_clf.predict, X_lin, y_binary_subset, axes, 0, 1)\n",
    "svs = lin_svm_clf.support_vectors_\n",
    "plt.scatter(svs[:, 0], svs[:, 1], s=1, facecolors='#009900', label='support vectors')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d39d0d35b940976baa5d09a498c1c01f",
     "grade": false,
     "grade_id": "cell-9ba0f8b1c083f050",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.03)** Is the data linearly separable?\n",
    "Do we hence use a hard margin or a soft margin SVM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d180d5356076108d60aca472de7851d4",
     "grade": false,
     "grade_id": "cell-6936a4bdba0b0d19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#uncomment the correct answers\n",
    "\n",
    "#linearly_separable = 'yes'\n",
    "#linearly_separable = 'no'\n",
    "\n",
    "#SVM_margin = 'hard'\n",
    "#SVM_margin = 'soft'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "49e45fcbcb596ae9a40533d6c0d64f5f",
     "grade": true,
     "grade_id": "cell-c498612561b2cd60",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'linearly_separable' in locals()\n",
    "assert 'SVM_margin' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f511e19c4c6ca13ab71894c77f4c41ec",
     "grade": false,
     "grade_id": "cell-18630899c33c7443",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.04) Linear SVM implementation:**  We are using CVXOPT to solve the Quadratic Programming (QP) problem. According to https://cvxopt.org/userguide/coneprog.html#quadratic-programming the optimization problem needs to be in the following form\n",
    "\n",
    "$$\\begin{array}[t]{ll}\\mbox{minimize} & (1/2) x^TPx + q^T x \\\\\\mbox{subject to} & Gx \\preceq h \\\\ & Ax = b\\end{array}$$\n",
    "\n",
    "with the corresponding API\n",
    "`cvxopt.solvers.qp(P, q[, G, h[, A, b[, solver[, initvals]]]])`\n",
    "\n",
    "The dual form of the **hard margin** linear SVM objective is (page **189** (3rd edition), of the book)\n",
    "\n",
    "$$\\underset{\\alpha}{\\mbox{minimize}} \\hspace{0.2cm} \\frac{1}{2} \\sum_{i}^m \\sum_{j}^m \\alpha^{(i)}\\alpha^{(j)}t^{(i)}t^{(j)}\\mathbf{x}^{(i)\\mathsf{T}}\\mathbf{x}^{(j)}  - \\sum_{i=1}^m \\alpha^{(i)}$$\n",
    "$$\\begin{array} \\\\\\mbox{subject to} & \\alpha^{(i)} \\geq 0 \\\\ & \\sum_i^m \\alpha^{(i)} t^{(i)} = 0\\end{array}$$\n",
    "\n",
    "Rewriting the SVM objective in vector/matrix form, and changing the constraint to the correct form, we get\n",
    "\n",
    "$$\\hspace{1.3cm}\\underset{\\alpha}{\\mbox{minimize}} \\hspace{0.4cm} \\frac{1}{2} \\boldsymbol{\\alpha}^{\\mathsf{T}} \\mathbf{H} \\boldsymbol{\\alpha} -  \\mathbf{1}^{\\mathsf{T}}\\boldsymbol{\\alpha}$$\n",
    "$$\\begin{array}\\\\\\mbox{subject to} & -\\boldsymbol{\\alpha} \\leq \\boldsymbol{0} \\\\ & \\mathbf{t}^{\\mathsf{T}}\\boldsymbol{\\alpha} = 0 \\end{array}$$\n",
    "where matrix $\\mathbf{H}$ has elements $H_{i,j} = t^{(i)}t^{(j)}\\mathbf{x}^{(i)\\mathsf{T}}\\mathbf{x}^{(j)}$.\n",
    "\n",
    "Finally, this implementation of an **SVM expects labels/targets with -1 for one class and +1 for the other**, so we need to change the labels accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Let's map the training class labels from {0, +1} to {-1, +1}.\n",
    "# These labels should be used in the SVM optimization!\n",
    "t_train_svm = 2.*y_train - 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "095f8052902eb234b3f4d891074d5143",
     "grade": false,
     "grade_id": "cell-11df6664af20d70d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Map the terms from the SVM objective to the CVXOPT syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc178cbba96e7ff9e7541f1d0e4cb6aa",
     "grade": false,
     "grade_id": "cell-019330c6e32789d9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# use 'alpha', 'H', 't transposed', 'ones', 'identity', 'zero', 'zeros'\n",
    "# for negtive values '-alpha' etc.\n",
    "x = '?'\n",
    "P = '?'\n",
    "q = '?'\n",
    "G = '?'\n",
    "h = '?'\n",
    "A = '?'\n",
    "b = '?'\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ffb182932c25767a0cc0baaedda2895",
     "grade": true,
     "grade_id": "cell-3c4be1b71c0d205e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert x != '?'\n",
    "assert P != '?'\n",
    "assert q != '?'\n",
    "assert G != '?'\n",
    "assert h != '?'\n",
    "assert A != '?'\n",
    "assert b != '?'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3fff02cc2596b06b49125c17ea69726b",
     "grade": false,
     "grade_id": "cell-b5fb1c4ed0c65b4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.05)** For the **soft margin** linear SVM the constraint changes to $C \\geq \\alpha^{(i)} \\geq 0$ so we get\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\min_{\\alpha} & \\frac{1}{2} \\boldsymbol{\\alpha}^{\\mathsf{T}} \\mathbf{H} \\boldsymbol{\\alpha} -  \\mathbf{1}^{\\mathsf{T}}\\boldsymbol{\\alpha}\n",
    "    \\\\\n",
    "     \\textrm{subject to } & -\\boldsymbol{\\alpha} \\leq \\boldsymbol{0} \n",
    "    \\\\\n",
    "     & \\boldsymbol{\\alpha} \\leq \\boldsymbol{C}\n",
    "     \\\\\n",
    "     & \\mathbf{t}^{\\mathsf{T}}\\boldsymbol{\\alpha} = 0  \n",
    "\\end{aligned}$$\n",
    "where the two inequalities can be stacked in a combined matrix/vector `G` and `h`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1cc7c8f15b622fbf5ddf1b09660d8859",
     "grade": false,
     "grade_id": "cell-3a5e016e3b9cedd0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.06)** Before feeding all of this information to CVXOPT to optimize a **soft margin** SVM with our data, the only remaining question has to be answered: \"How can we efficiently calculate $\\mathbf{H}$?\" Let's consider a simple example with 2 samples $\\{x^{(1)}, x^{(2)}\\} \\in \\mathbb{R}^2$ which are two dimensional vectors. i.e. $\\mathbf{x}^{(1)} = (x_1^{(1)} , x_2^{(1)})^\\mathsf{T}$\n",
    "\n",
    "$$X = \\begin{bmatrix} x_1^{(1)} & x_2^{(1)} \\\\ x_1^{(2)} & x_2^{(2)} \\end{bmatrix} \\ \\ \\ t = \\begin{bmatrix} t^{(1)}  \\\\ t^{(2)} \\end{bmatrix}$$\n",
    "\n",
    "We now proceed to create a new matrix $\\mathbf{X}'$ where each input sample $\\mathbf{x}$ is multiplied by the corresponding output label $t$. This can be done easily in Numpy using vectorization and padding.\n",
    "\n",
    "$$\\mathbf{X}' = \\begin{bmatrix} x^{(1)}_1 t^{(1)} & x^{(1)}_2t^{(1)} \\\\\n",
    "x^{(2)}_1t^{(2)} & x^{(2)}_2t^{(2)} \\end{bmatrix}$$\n",
    "\n",
    "Finally we take the matrix multiplication of $\\mathbf{X}'$ and its transpose giving\n",
    "\n",
    "$$\\mathbf{H} = {\\mathbf{X}'} {\\mathbf{X}'^\\mathsf{T}} = \\begin{bmatrix} x^{(1)}_1 t^{(1)} & x^{(1)}_2t^{(1)} \\\\\n",
    "x^{(2)}_1t^{(2)} & x^{(2)}_2t^{(2)} \\end{bmatrix} \\begin{bmatrix} x^{(1)}_1 t^{(1)} & x^{(2)}_1 t^{(2)}  \\\\\n",
    "x^{(1)}_2t^{(1)} & x^{(2)}_2t^{(2)} \\end{bmatrix}$$\n",
    "\n",
    "$$\\mathbf{H} = \\begin{bmatrix}  x^{(1)}_1 x^{(1)}_1t^{(1)}t^{(1)} + x^{(1)}_2x^{(1)}_2t^{(1)}t^{(1)} & x^{(1)}_1 x^{(2)}_1t^{(1)}t^{(2)} + x^{(1)}_2x^{(2)}_2t^{(1)}t^{(2)} \\\\ x^{(2)}_1 x^{(1)}_1t^{(2)}t^{(1)} + x^{(2)}_2x^{(1)}_2t^{(2)}t^{(1)} & x^{(2)}_1 x^{(2)}_1t^{(2)}t^{(2)} + x^{(2)}_2x^{(2)}_2t^{(2)}t^{(2)} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5aa88afe30f3cc868bf941bf38092c2",
     "grade": false,
     "grade_id": "cell-33e302cc29da46ec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.1.07) Install cvxopt ####\n",
    "The `homl3` environment does not include a solver for QPs. So we need to install an additional package. This is easy to do on a command line with\n",
    "`conda install --channel \"conda-forge\" cvxopt` (do not forget to activate the `homl3` environment before running the command).\n",
    "Or you can try `pip install cvxopt` before using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "54b6e76b3a561978b14847c0236f549c",
     "grade": false,
     "grade_id": "cell-0dd1bd64a9a8ac8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.08) Begin implementation:** Let's import <code>cvxopt</code>, define a soft margin weight <code>C</code>, and get the dimensionality of our training data <code>mxn</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d3c61c4d45a8776f9374ac66d48685ca",
     "grade": false,
     "grade_id": "cell-93894b3e78261818",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Importing with custom names to avoid issues with numpy / sympy matrix\n",
    "from cvxopt import matrix as cvxopt_matrix\n",
    "from cvxopt import solvers as cvxopt_solvers\n",
    "\n",
    "#Initializing values\n",
    "C = 2\n",
    "m,n = X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a01b9942267b893c70b06ee9553ec670",
     "grade": false,
     "grade_id": "cell-7a0c64a81502c316",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.09)** Following the hints from 2.1.06) calculate <code>H</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e12bb24dd4699c45d7a05e40c9be921d",
     "grade": false,
     "grade_id": "cell-4a79f06c849d59da",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "H = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9aced0e85d211a11160d82bee4010575",
     "grade": true,
     "grade_id": "cell-9cc7f82127b8848b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert H.shape[0] == 1453\n",
    "assert H.shape[1] == 1453\n",
    "assert H[0,0] == 1.265625\n",
    "assert H[-1,-1] == 0.5625"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2af766296cb9d61bbe50a118a238f5b8",
     "grade": false,
     "grade_id": "cell-50311856543fd10b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.10)** Calculate/define <code>P</code>, <code>q</code>, <code>G</code>, <code>h</code>, <code>A</code> and <code>b</code>.\n",
    "\n",
    "NOTE: <code>G</code> and <code>h</code> should be formulated w.r.t. the soft margin constraint as seen in 2.1.05)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9985af4f20ade93d08f6a28703892c4",
     "grade": false,
     "grade_id": "cell-18c8091cbf810d2d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "P = None\n",
    "q = None\n",
    "G = None\n",
    "h = None\n",
    "A = None\n",
    "b = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "print(G.shape)\n",
    "print(h.shape)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "decc8f9ded889a77928382f22632dce4",
     "grade": true,
     "grade_id": "cell-f0a62a2221a2ec3c",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert P.shape[0] == 1453\n",
    "assert P.shape[1] == 1453\n",
    "\n",
    "assert q.shape[0] == 1453\n",
    "assert q.shape[1] == 1\n",
    "assert q[0,0] == -1\n",
    "\n",
    "assert G.shape[0] == 2906\n",
    "assert G.shape[1] == 1453\n",
    "assert G[-1,-1] == 1.0\n",
    "\n",
    "assert h.shape[0] == 2906\n",
    "assert h.ndim == 1\n",
    "assert h[0] == 0.0\n",
    "\n",
    "assert A.shape[0] == 1\n",
    "assert A.shape[1] == 1453\n",
    "assert A[0,0] == 1.0\n",
    "\n",
    "assert b.shape[0] == 1\n",
    "assert b.ndim == 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#if you are stuck here, uncomment the lines below to load variables\n",
    "\n",
    "# npzfile = np.load('./get_unstuck/cvxopt.npz')\n",
    "# P = npzfile['P']\n",
    "# q = npzfile['q']\n",
    "# G = npzfile['G']\n",
    "# h = npzfile['h']\n",
    "# A = npzfile['A']\n",
    "# b = npzfile['b']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a4040bbea8a6bd0bb831edcd4e8fbc6d",
     "grade": false,
     "grade_id": "cell-e13535b615000caa",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.11)** Now we are almost ready to run the solver..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1104f374c13c5ec5ce094514fe9f555d",
     "grade": false,
     "grade_id": "cell-6dab062bafd57b64",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#Converting into cvxopt format\n",
    "P = cvxopt_matrix(P)\n",
    "q = cvxopt_matrix(q)\n",
    "G = cvxopt_matrix(G)\n",
    "h = cvxopt_matrix(h)\n",
    "A = cvxopt_matrix(A)\n",
    "b = cvxopt_matrix(b)\n",
    "\n",
    "#Setting solver parameters \n",
    "cvxopt_solvers.options['show_progress'] = True\n",
    "cvxopt_solvers.options['abstol'] = 1e-10\n",
    "cvxopt_solvers.options['reltol'] = 1e-10\n",
    "cvxopt_solvers.options['feastol'] = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f51589481724a4d9b61c43fca9f3fb77",
     "grade": false,
     "grade_id": "cell-ada8d93154bf5320",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.12)** Run the solver and store the results in `sol`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7d127f47779a283d3b6f0e269c41570",
     "grade": false,
     "grade_id": "cell-9b524cbbbe4b23b4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sol = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "alphas = np.array(sol['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "866d021aab04c38977551f0b7fbc6d4f",
     "grade": true,
     "grade_id": "cell-12a49d56e5d129b2",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(sol, dict)\n",
    "assert 'primal objective' in sol.keys()\n",
    "assert alphas.shape[0] == 1453\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "730039986b49d964efaf973481365a63",
     "grade": false,
     "grade_id": "cell-adbc2b8bd17ba02e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.13)** Calculate `w_svm` and `b_svm` (see page **190**, 3rd edition, of the book. More information can be also found in Appendix C, 2nd edition.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "03991bdd54a53ae1bd48c2cd377fb943",
     "grade": false,
     "grade_id": "cell-5b6e3d887dcd32d6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#==================Computing parameters===============================#\n",
    "# Use a threshold of 1e-4 for alpha (rather than 0) for computing b_svm\n",
    "\n",
    "w_svm = None\n",
    "b_svm = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Display results\n",
    "w_svm = w_svm.flatten()\n",
    "print('w = ', w_svm)\n",
    "print('b = ', b_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e433cffd6fd840b28232297c2f8d3750",
     "grade": true,
     "grade_id": "cell-2637a561213c57ff",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.abs(w_svm[0] + 0.42666667) < 1e-6\n",
    "assert np.abs(b_svm - 2.06127472524322) < 1e-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b42dc7e780929d918cdca50952be9beb",
     "grade": false,
     "grade_id": "cell-2e086eb5ff8abc3b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.14)** Implement the SVC prediction (see page **186**, 3rd edition). Note that the predicted labels should be 0 and 1, not -1 and +1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7456bb124f068c8284f99cb54785eb17",
     "grade": false,
     "grade_id": "cell-0aaed0932cd77be5",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def own_svm_predict(b,w,X):\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6a7660e9f0332a072a16c5209c2aa2b4",
     "grade": true,
     "grade_id": "cell-b92088e8b41e4145",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert (own_svm_predict(1, np.array([2, 3]), np.array([[4, 5], [-5, 0]])) == np.array([1, 0])).all()\n",
    "assert (own_svm_predict(-1, np.array([0, 1]), np.array([[-5, 0], [1, 0]])) == np.array([0, 0])).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5942559f348d43f0a7f8183eb79d50a6",
     "grade": false,
     "grade_id": "cell-86ba206969f3ccb6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "own_svm_y_pred = own_svm_predict(b_svm,w_svm,X_test)\n",
    "print_accuracy_confusion(y_test, own_svm_y_pred, 'own_svm')\n",
    "\n",
    "# A few lines to make own_svm_predict work with plot_feature_space_function (without implementing a fullblown sklearn calssifier)\n",
    "import functools\n",
    "own_svm_predict_param = functools.partial(own_svm_predict, b_svm, w_svm)\n",
    "\n",
    "plot_feature_space_function(own_svm_predict_param, X_lin, y_binary_subset, axes, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "99549e0fbcd7e686ec88ac8b7e4f93f6",
     "grade": false,
     "grade_id": "cell-eb09ad784e0508a5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.1.15)** Let's compare our solution to the one from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f06206b9f654a6b12509f6f6d9f874c",
     "grade": false,
     "grade_id": "cell-12a93884abb386fb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('w = ',lin_svm_clf.coef_)\n",
    "print('b = ',lin_svm_clf.intercept_)\n",
    "\n",
    "print_accuracy_confusion(y_test, lin_svm_y_pred, 'lin_svm')\n",
    "plot_feature_space_function(lin_svm_clf.predict, X_lin, y_binary_subset, axes, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ab5c6214feec5ba084c8d6e0fd68586d",
     "grade": false,
     "grade_id": "cell-7f0e247df65f8b16",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Both the accuracy and the `w` parameter values should be close. Small differences occur depending on how the optimization is done (e.g., tolerances).\n",
    "\n",
    "If you are interested in how this method is modified to build non-linear SVMs using the *kernel trick*, read pages **190-193**, 3rd edition, of the book."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "799f3c849b18056dfdcbbfd8ebc9ea22",
     "grade": false,
     "grade_id": "cell-42b06e042af1fd8a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Linear SVM implementation based on https://xavierbourretsicotte.github.io/SVM_implementation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "74bb3a803add59714958666ae1480798",
     "grade": false,
     "grade_id": "cell-77acb04a49583f46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 2.2) Voting classifier\n",
    "\n",
    "We already tried quite a few classifiers on this data set. Let's try to combine them in an ensemble (chapter 7 of the book).\n",
    "\n",
    "First we'll define two more classifiers for the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83f70025761e354929b6677966707c46",
     "grade": false,
     "grade_id": "cell-29808b1082deeb73",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_y_pred = rf_clf.predict(X_test)\n",
    "print_accuracy_confusion(y_test, rf_y_pred, 'rf')\n",
    "plot_feature_space_function(rf_clf.predict, X_lin, y_binary_subset, axes, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "326c2346636f38483963230b055a416d",
     "grade": false,
     "grade_id": "cell-3eb33bc5caf92dc2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(5)\n",
    "knn_clf.fit(X_train, y_train)\n",
    "knn_y_pred = knn_clf.predict(X_test)\n",
    "print_accuracy_confusion(y_test, knn_y_pred, 'knn')\n",
    "plot_feature_space_function(knn_clf.predict, X_lin, y_binary_subset, axes, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "577d21f9790f1cbd1e568cbf9a1ba2ed",
     "grade": false,
     "grade_id": "cell-ad0a7b6b56d1f422",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.2.01)** Combine (concatenate) the predictions of the SGD classifier `sgd_clf` (we implemented before looking into how to implement a linear SVM), the random forest `rf_clf`, and of the KNN `knn_clf` in one variable `combined_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "57bc73c2a40e0ee8a4df85e5f7541afa",
     "grade": false,
     "grade_id": "cell-8d13a36a3a68036d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "combined_pred = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "71f6fd8d9644a3ef10cad38e44b0296e",
     "grade": true,
     "grade_id": "cell-5a0e2431fb4f0bb9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert combined_pred.shape[0] == 3\n",
    "assert combined_pred.shape[1] == 485"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7ec1e576f396a48eb99af45e17a203d8",
     "grade": false,
     "grade_id": "cell-43c40cdcb7b02965",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.2.02)** Implement hard voting, i.e., generate a new variable `hard_voting_pred` where the prediction corresponds to that of the majority of the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6062380c9200582326fe44c768facf6e",
     "grade": false,
     "grade_id": "cell-f3a52970a1dabc79",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# hint: use a `mode` function from scipy\n",
    "\n",
    "hard_voting_pred = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "print_accuracy_confusion(y_test, hard_voting_pred, 'hard_voting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "85ae459d366ed87e85ae19406f19a1cc",
     "grade": true,
     "grade_id": "cell-d65b28fe6dbe2db6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert hard_voting_pred.shape[0] == 485\n",
    "assert hard_voting_pred.ndim == 1 or hard_voting_pred.shape[1] == 1\n",
    "assert accuracy_score(y_test, hard_voting_pred) > 0.8927"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f643ce0e7418e718b03560a1ffda0dc2",
     "grade": false,
     "grade_id": "cell-eeaaf7ec19ae29da",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**2.2.03)** Even this very simple voting approach brings the 3 classifiers that don't perform that well individually to the same level as your best performing classifier we had so far, the linear SVM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f64a5d1934277f3d6f70068438ff4450",
     "grade": false,
     "grade_id": "cell-3325f249f44d44c6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 2.2.04) Bagging \n",
    "Now let's see what we can do with an ensemble of just our worst performing classifier, the SGD. The code is already provided below, your task is to adjust the parameters such that it beats the linear SVM by getting an accuracy >0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "560b2c8c785fe35ef892a46774bcc4ae",
     "grade": false,
     "grade_id": "cell-fa0dcba5997172ba",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Bagging\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "n_estimators=1\n",
    "max_samples=1000\n",
    "bootstrap=False\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "bag_clf = BaggingClassifier(SGDClassifier(random_state=0),\n",
    "                            n_estimators=n_estimators,\n",
    "                            max_samples=max_samples, \n",
    "                            bootstrap=bootstrap, \n",
    "                            random_state=0)\n",
    "\n",
    "bag_clf.fit(X_train, y_train)\n",
    "bag_y_pred = bag_clf.predict(X_test)\n",
    "\n",
    "print_accuracy_confusion(y_test, bag_y_pred, 'bag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59cd431591081323fda364d58f8e0e76",
     "grade": true,
     "grade_id": "cell-c1f8c0c9f7654358",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert accuracy_score(y_test, bag_y_pred) > 0.9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e62e4306092a19562915eab265ea45f7",
     "grade": false,
     "grade_id": "cell-0c8be4495415555f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3) Imitation Learning for Motion Planning\n",
    "\n",
    "In the last section of this practicum, we will use our machine learning knowledge in a robotics example.\n",
    "\n",
    "#### Motion Planning\n",
    "Motion planning is a field of robotics in which robots have to plan and execute a trajectory in order to reach a goal. The following image shows the Mirte planning a path to reach its goal while avoiding obstacles.\n",
    "\n",
    "<center><img src=\"img/Mirte.png\" alt=\"drawing\" width=\"400\"/></center>\n",
    "\n",
    "Commonly, these algorithms have to be designed and tuned by someone with knowledge in robotics and/or control. However, if we aim to have robots in our daily life outside industrial settings, such an approach becomes limiting, because it is not feasible to have a roboticist tuning every robot for every different situation.\n",
    "\n",
    "#### Imitation Learning\n",
    "Imitation Learning is a promising line of research that could address this problem. Imitation Learning can give humans, that are not experts in robotics/control, the ability to program a robot. The idea is simple, a human provides a set of demonstrations of a task, and a robot imitates her/him.\n",
    "\n",
    "#### Goal\n",
    "\n",
    "Build a Motion Planning algorithm that uses an Imitation Learning technique, called Behavioral Cloning, to fit a classifier, using Supervised Learning, to demonstrations provided by an *oracle*.\n",
    "\n",
    "* **Oracle:** a system that provides demonstrations of a task. In our framing of the problem the oracle is a human. However, for practical reasons, in this assignment we are going to use a Motion Planning algorithm (Artificial Potential Fields, implementation from https://atsushisakai.github.io/PythonRobotics/modules/path_planning/grid_base_search/grid_base_search.html#potential-field-algorithm) as an oracle, and given that we are going to imitate its behavior, it is not required for you to know how this method works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8b04ba9be227aaac065e1ea7855405bc",
     "grade": false,
     "grade_id": "cell-010258c8925bee56",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from potential_field_planning import create_environment, potential_field_planning, classifier_planning, plot_environment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e575ead79309817774c2f4def475f955",
     "grade": false,
     "grade_id": "cell-28b1160f8052cbd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.01)** The function `create_environment` randomly generates a 2D environment that consists of a starting point `[sx, sy]`, a goal `[gx, gy]`, and obstacles `[ox, oy]`. The dimensionality of `ox` and `oy` is equal to the number of obstacles. \n",
    "\n",
    "Let's create an environment with one obstacle.\n",
    "\n",
    "*Note: this function only supports 1, 2 or 3 obstacles.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a3a1fbb2e174096d086d29c659ef098",
     "grade": false,
     "grade_id": "cell-d82fcc0a45c97f44",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "env = create_environment(n_obstacles=1, seed=1)\n",
    "\n",
    "print('Start              :', [env.sx, env.sy])\n",
    "print('Goal               :', [env.gx, env.gy])\n",
    "print('Obstacles x-coords  :', env.ox)\n",
    "print('Obstacles y-coords  :', env.oy)\n",
    "print('Number of obstacles:', len(env.ox))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4d5fdccf17e248131b4ce61de7881631",
     "grade": false,
     "grade_id": "cell-b5d4ae760f6eb2d0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**IMPORTANT:** do not modify the seed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8ca22056fbd30a011b1a0cef60123fbd",
     "grade": false,
     "grade_id": "cell-0a6012dd5ae53f93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The function `potential_field_planning` is the oracle. It takes as input the parameters of our environment and generates a collision-free path to the goal. The generated trajectory is saved in `trajectory`.\n",
    "\n",
    "The function `plot_environment` can be used to visualize the environment, namely the obstacles (blue circles), start and goal position, and the trajectory.\n",
    "\n",
    "**3.02)** Let's generate a trajectory with the oracle and visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7536f29424dffb122538c8ea6a4d4f8a",
     "grade": false,
     "grade_id": "cell-e46c56e78b24f27a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Generate trajectory\n",
    "trajectory = potential_field_planning(env)\n",
    "\n",
    "# Show environment and trajectory\n",
    "plot_environment(env, potential_field_trajectory=trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "eb72bc5403edd34d2a1493c396824ef8",
     "grade": false,
     "grade_id": "cell-bfc51143f6bdcdb9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3.03) Dataset\n",
    "\n",
    "We can get trajectories from our oracle in multiple environments to build a dataset to train a classifier.\n",
    "\n",
    "\n",
    "**Input:** In this context, the input of our machine learning model corresponds to the *robot's state* at a specific moment in time of the environment. Each one of these *moments* are known as time steps, and for every time step, as a function of the robot's state, our machine learning method has to make a decision on where to go next. \n",
    "\n",
    "**robot's state** = [gxd, gyd, oxd1,...,oxdn, oyd1, ..., oydn]\n",
    "\n",
    "* **gxd**:  x distance from robot to goal\n",
    "* **gyd**:  y distance from robot to goal\n",
    "* **oxdi**: x distance from robot to obstacle i\n",
    "* **oydi**: y distance from robot to obstacle i\n",
    "\n",
    "**Output:** We are going to solve this problem as a classification problem. Each class corresponds to an *action* that the robot can take i.e., where to go next. These classes are represented using a vector that indicates the directions in which the robot can move.\n",
    "\n",
    "**actions** = north, east, south, west, north-east, north-west, south-east, south-west. Represented with numbers from 0 to 7 respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb1e5a2785cd9322b50bedd48a8fdb9b",
     "grade": false,
     "grade_id": "cell-12f5c57ca1e44f3c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.03)** `trajectory` is a dictionary that contains the following information:\n",
    "* `state`: the set of states visited by the robot. Each row of the state vector corresponds to the state of the robot in a specific time step. \n",
    "* `action`: the set of actions taken by the robot in every time step.\n",
    "* `pos`: the positions that the robot visited, as visualized in the plot.\n",
    "* `success`: a boolean indicating if the goal state was reached\n",
    "* `collision`: a boolean indicating if the robot collided.\n",
    "\n",
    "These names can be used as keys to access the data in the dictionary. \n",
    "\n",
    "Get the states and actions from `trajectory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9703c61b16c9d80075402490f94bdf80",
     "grade": false,
     "grade_id": "cell-5f04d5142366aa70",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "states = None\n",
    "actions = None\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff8d9e0e3efb3fcfd67fefa6bc3c2945",
     "grade": true,
     "grade_id": "cell-b7316513f73d4742",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.abs(states[0, 1] + 4.66150302) < 1e-6\n",
    "assert np.abs(states[4, 3] + 1.38529445) < 1e-6\n",
    "assert np.abs(states[10, 2] + 1.68430939) < 1e-6\n",
    "assert actions is not None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8442943fef11a42adbbd64fe41dd19ac",
     "grade": false,
     "grade_id": "cell-edcd6eabb64a932f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.04)** As mentioned before, the dimensionality of our state vector is a function of the number of obstacles in the environment. \n",
    "\n",
    "Build a function that computes the state dimensionality as a function of n obstacles:\n",
    "\n",
    "*Note: this function has to be solved with an equation.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da1d817aead0c07701ed187b431860db",
     "grade": false,
     "grade_id": "cell-fe9c25792eb14fc7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_state_dim(n_obstacles):\n",
    "    state_dim = None\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "36a80166311f43c34d7a62a859c35c14",
     "grade": true,
     "grade_id": "cell-e77d189ca944bab0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert get_state_dim(2) == 6\n",
    "assert get_state_dim(4) == 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0224d14af8deb772109d93a6d188804",
     "grade": false,
     "grade_id": "cell-ffe23b0669baac13",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "scrolled": true
   },
   "source": [
    "**3.05)** Build a function called `generate_dataset` that repeats the following process n times:\n",
    "\n",
    "    1) Create an environment.\n",
    "\n",
    "    2) Get a demonstration from the oracle.\n",
    "\n",
    "    3) Save demonstration, i.e., append visited states into an array called states and taken actions into an \n",
    "    array called actions.\n",
    "\n",
    "The argument `ds_n_obstacles` indicates the number of obstacles the created environments will have, `n_trajectories` corresponds to the number of times the loop above will be repeated, and `show` is a boolean that makes the saved trajectories visible when true.\n",
    "\n",
    "Wherever it says `MODIFY`, you should modify the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad9a3f296e5a7f57ee1e99f5c92bce34",
     "grade": false,
     "grade_id": "cell-b9049bf3fa7c8a7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_dataset(ds_n_obstacles, n_trajectories, show=True):\n",
    "    np.random.seed(18)  # reproducibility, do not change\n",
    "    \n",
    "    # Initialize our arrays\n",
    "    states = np.empty([0, get_state_dim(ds_n_obstacles)])\n",
    "    actions = np.empty([0])\n",
    "    \n",
    "    if show:\n",
    "        # Create lists used for interactive animation\n",
    "        envs = []\n",
    "        trajectories = []\n",
    "       \n",
    "    for i in range(n_trajectories):            \n",
    "        # Create environment\n",
    "        ds_seed = np.random.randint(low=0, high=1e6)  # use this seed to create the environment\n",
    "        env = None  # MODIFY\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Run planner and get a trajectory\n",
    "        trajectory = None  # MODIFY\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        if show:\n",
    "            # Store generated data for use in interactive animation\n",
    "            envs.append(env)\n",
    "            trajectories.append(trajectory)\n",
    "\n",
    "        # Append data to arrays states and actions. \n",
    "        states = states # MODIFY, not None because it already exists\n",
    "        actions = actions # MODIFY, not None because it already exists\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        # Print progress\n",
    "        if (i + 1) % (n_trajectories // 5 + 1e-6) == 0:\n",
    "            print('Progress dataset: %d %%' % ((i + 1) / n_trajectories * 100))\n",
    "\n",
    "    if show:\n",
    "        # Generate an interactive ipython widget to visualize the generated environments and trajectories\n",
    "        def plot_train_track(i):\n",
    "            plot_environment(envs[i], potential_field_trajectory=trajectories[i])\n",
    "            plt.title(f'dataset trajectory {i}')\n",
    "        ipywidgets.interact(plot_train_track, i=(0,n_trajectories - 1))\n",
    "    \n",
    "    return states, actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1a24af8b86d80b51e296db1ed3e809e8",
     "grade": false,
     "grade_id": "cell-478952a18d06b99e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Create a dataset with 5 trajectories and 1 obstacle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "states, actions = generate_dataset(ds_n_obstacles=1, n_trajectories=5, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bd1e5354d99e18eb6dcf1f1de74000e0",
     "grade": true,
     "grade_id": "cell-8c77aa1bedf73c0d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert actions.shape == (77,)\n",
    "assert states.shape == (77, 4)\n",
    "assert np.abs(states[43, 3] - -0.142548887) < 1e-6\n",
    "assert int(actions[60]) == 7\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "77338c13c29e151e6b728584d5f734a1",
     "grade": false,
     "grade_id": "cell-3933a85a2037f8c8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3.06) Prepare data\n",
    "\n",
    "After collecting a dataset, it is necessary to prepare the data for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "19bf6ce4808f3f4c76cbe98ab3b5e507",
     "grade": false,
     "grade_id": "cell-17daed588b7827d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.07)** In the collected dataset, the values `states[i, :]`, `states[i+1, :]` and `states[i+2, :]` are correlated (in most of the cases), because they are state transitions obtained in the same demonstration. This brakes an important machine learning assumption, which one? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7abf52d52fc2998d7e1542380bc2cdb9",
     "grade": false,
     "grade_id": "cell-7d8b147a508e8ed4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the correct answer\n",
    "\n",
    "#answer1 = 'the dataset is big and diverse enough, so our input space is properly represented'\n",
    "#answer1 = 'the data has a linear relationship'\n",
    "#answer1 = 'the data is i.i.d'\n",
    "#answer1 = 'the kernel trick'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f99e8380b52638e5c6869114c8c8dd7",
     "grade": true,
     "grade_id": "cell-d688ecea475dbb89",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer1' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dd704fb1a6dbbfb17ea856de92eb1b6b",
     "grade": false,
     "grade_id": "cell-7b5f0b940326f793",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "This problem is alleviated when we randomly sample from our dataset during training; however, we have to be careful to shuffle the dataset before splitting it into training and test; otherwise, the data in these sets will be highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c7ce526bcf86a41916830be42960104",
     "grade": false,
     "grade_id": "cell-1a1c11427aaa8933",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c236aea0f28ec293c66bec7b849aa25e",
     "grade": false,
     "grade_id": "cell-d81616228e4cd3bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.08)** Using the above imported functions, build the function `data_preprocess`, which takes as an argument the `states` and `actions` arrays generated with `generate_dataset` function. The outputs must be scaled accordinig to fitted `standardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed461f4b85388fd6609aa1739d2752ec",
     "grade": false,
     "grade_id": "cell-e30aba37a3cfe3b6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def data_preprocess(states, actions): \n",
    "    # Shuffle data with random_state=0\n",
    "    shuffled_states, shuffled_actions = None, None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Separate data into train and test (20% of the data for test set with random_state=0)\n",
    "    states_train, states_test, actions_train, actions_test = None, None, None, None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Scale training and test data (remember that test data should never be used to fit data)\n",
    "    states_train_scaled = None  # MODIFY\n",
    "    states_test_scaled = None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return states_train_scaled, states_test_scaled, actions_train, actions_test, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#if you are stuck here, uncomment the lines below to load variables\n",
    "\n",
    "# npzfile = np.load('./get_unstuck/states_actions.npz')\n",
    "# states = npzfile['states']\n",
    "# actions= npzfile['actions']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9b49e113f1b4e5228418b8af75c61558",
     "grade": false,
     "grade_id": "cell-1e85a4b920f0cd08",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.09)** Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "655418841765cadb6b63b105a05790d3",
     "grade": false,
     "grade_id": "cell-d0ac13be97af0c52",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "states_train_scaled, states_test_scaled, actions_train, actions_test, scaler = data_preprocess(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e1f2782083f5c78242bc563d4b82b299",
     "grade": true,
     "grade_id": "cell-a95a7826cc24b0db",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert states_train_scaled.shape == (61, 4)\n",
    "assert states_test_scaled.shape == (16, 4)\n",
    "assert actions_train.shape == (61,)\n",
    "assert actions_test.shape ==(16,)\n",
    "assert np.abs(states_train_scaled[10, 0] - 0.986126195) < 1e-6\n",
    "assert np.abs(states_test_scaled[4, 3] + 0.129293968) < 1e-6\n",
    "assert int(actions_train[43]) == 7\n",
    "assert int(actions_test[3]) == 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4a845431e2ba8a6d0677ba232f1a3ae6",
     "grade": false,
     "grade_id": "cell-8aa301681485592d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3.10) Train classifier \n",
    "Build the function `train_classifier` that trains a classifier directly from `states` and `actions` and gets its accuracy score and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "82b55a312cc9ebed58b139653b59801a",
     "grade": false,
     "grade_id": "cell-623a5a1c0d3ec2c9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d18e6c6870be39d0428877b2469f197",
     "grade": false,
     "grade_id": "cell-95f17a9265c328eb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train_classifier(states, actions):\n",
    "    # Prepare data\n",
    "    states_train_scaled, states_test_scaled, actions_train, actions_test, scaler = None, None, None, None, None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Train Random Forest with random_state=0\n",
    "    clf = None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    # Predict using test data\n",
    "    actions_test_pred = None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Get accuracy score\n",
    "    accuracy = None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "    # Plot confusion matrix\n",
    "    conf_matrix = None  # MODIFY\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    print(f'Accuracy: {accuracy:.3f}')\n",
    "    print('\\nConfusion matrix:\\n\\n', conf_matrix)\n",
    "    \n",
    "    return clf, accuracy, conf_matrix, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a900e61413c9124b77fd2d1097cb04e6",
     "grade": false,
     "grade_id": "cell-58dfc4a4af62d43c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "clf, accuracy, conf_matrix, scaler = train_classifier(states, actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eb7f84e35f7797ea47c9f70eec82338b",
     "grade": true,
     "grade_id": "cell-d3c96e234a0f22d4",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert np.abs(accuracy - 0.9375) < 1e-6\n",
    "assert conf_matrix.shape == (8, 8)\n",
    "assert conf_matrix[3, 3] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "249c49c06154ec4b3e22c2b372f19088",
     "grade": false,
     "grade_id": "cell-aa2f3e49ea0c45df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.11)** There's something about the obtained confusion matrix that indicates that the state/input space of the learning problem is, probably, not properly covered. What is it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b98370b681f840e49ad6ed4684002703",
     "grade": false,
     "grade_id": "cell-98d4a0a086fc934e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the correct answer\n",
    "\n",
    "#answer2a = 'it is not symmetrical'\n",
    "#answer2a = 'it is sparse'\n",
    "#answer2a = 'some rows/columns only have zeros'\n",
    "#answer2a = 'it is not invertible'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2eb8b9b68bfba6bb71c98e14ba022bd1",
     "grade": true,
     "grade_id": "cell-b867f5cec6e87ffd",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer2a' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "which implies that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8c7e5991a4269a3c56e1c9c5859ac59b",
     "grade": false,
     "grade_id": "cell-3774edbda56ecbeb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the correct answer\n",
    "\n",
    "#answer2b = 'many actions are not represented'\n",
    "#answer2b = 'data is contradictory'\n",
    "#answer2b = 'total number of data instances is too small'\n",
    "#answer2b = 'training data is well balanced'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ab752476f06e9faa5c49f8c6af78852b",
     "grade": true,
     "grade_id": "cell-bfc266cbb2a29c76",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer2b' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "761cc136e6c3a9da217c3bfe040d5522",
     "grade": false,
     "grade_id": "cell-de29e81f387cf1e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### 3.12) Generate trajectories\n",
    "The classifier got a high accuracy, but we observed that the input/state space is not properly covered, let's see how it performs as a planner. \n",
    "\n",
    "The following function generates trajectories from a trained classifier and returns its success rate. \n",
    "\n",
    "* A trajectory is considered to be successful if it reaches the goal before a time limit and does not collide with any obstacle.\n",
    "\n",
    "* The `classifier_planning` function was imported at the beginning of the file and it creates a path using a classifier in a random environment. It returns a dictionary called `trajectory` (similar to `potential_field_planning`) but additionaly you can use the `success` and `collision` keys to check if the goal was reached.\n",
    "\n",
    "* If `show=True`, the function will show the classifier's trajectories in purple and the Artificial Potential Field planner trajectories in red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4d33ff51bdf1c12f3ed41a0388d1f317",
     "grade": false,
     "grade_id": "cell-e85110b891e06cd4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def generate_trajectories_classifier(clf, scaler, ds_n_obstacles, n_trajectories_test, show=True):\n",
    "    success_counter = 0  # count the number of times the robot reached the goal\n",
    "    np.random.seed(50)  # reproducibility \n",
    "\n",
    "    if show:\n",
    "        envs = []\n",
    "        trajectories = []\n",
    "    \n",
    "    for i in range(n_trajectories_test):\n",
    "        ds_seed = np.random.randint(low=0, high=1e6)\n",
    "        \n",
    "        # Create environment\n",
    "        env = create_environment(n_obstacles=ds_n_obstacles, seed=ds_seed)\n",
    "       \n",
    "        # Generate trajectory\n",
    "        trajectory = classifier_planning(env, clf, scaler)\n",
    "        success = trajectory['success']\n",
    "        \n",
    "        if show:\n",
    "            envs.append(env)\n",
    "            trajectories.append(trajectory)\n",
    "\n",
    "        # Count goal reached\n",
    "        if success:\n",
    "            success_counter += 1\n",
    "            \n",
    "        # Print if classifier fails\n",
    "        if not success:\n",
    "            print('Trial %i failed!' % i)\n",
    "            \n",
    "        # Print progress\n",
    "        if (i + 1) % int(n_trajectories_test  / 5) == 0:\n",
    "            print('Progress trials: %d %%' % ((i + 1) / n_trajectories_test * 100))\n",
    "    \n",
    "    success_rate = success_counter / n_trajectories_test\n",
    "    print('\\nSuccess rate: %.3f' % success_rate)\n",
    "    \n",
    "    if show:\n",
    "        def plot_test_track(i):\n",
    "            env = envs[i]\n",
    "            success = trajectories[i]['success']\n",
    "            collision = trajectories[i]['collision']\n",
    "\n",
    "            pf_trajectory = potential_field_planning(env)\n",
    "            plot_environment(env, potential_field_trajectory=pf_trajectory, classifier_trajectory=trajectories[i])\n",
    "            plt.title(f'test trajectory {i}, success={success}, collision={collision}')\n",
    "        ipywidgets.interact(plot_test_track, i=(0,n_trajectories_test-1))\n",
    "    \n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "43d62aae172c6d8840c5fe4b3c5cb26e",
     "grade": false,
     "grade_id": "cell-f776db65c715476b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.13)** Carefully read this function and answer the questions.\n",
    "\n",
    "**Q1:** What is the variable `n_trajectories_test`?\n",
    "\n",
    "**Q2:** Why does the `classifier_planning` function needs the `scaler` in one of its inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "919134cd06b2ccffc0263b3cf7013050",
     "grade": false,
     "grade_id": "cell-80dd8f9f21406f48",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# For each question uncomment on of the answers\n",
    "\n",
    "# Answer Q1\n",
    "\n",
    "#A1 = 'Number of environments to train the classifier'\n",
    "#A1 = 'Number of environments to test the classifier'\n",
    "#A1 = 'Number of environments in which the classifier was successful'\n",
    "#A1 = 'Number of environments in which the classifier failed'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "# Answer Q2\n",
    "#A2 = 'Because the environment has unscaled states, but the classifier expects scaled inputs'\n",
    "#A2 = 'Because the environment has scaled states, but the classifier expects unscaled inputs'\n",
    "#A2 = 'Because the classifier generates unscaled outputs, but the environment expects scaled actions'\n",
    "#A2 = 'Because the classifier generates scaled outputs, but the environment expects unscaled actions'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f55a6cba092a9e9b3acdf48b9e5e3c30",
     "grade": true,
     "grade_id": "cell-dc54636f309ddda9",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'A1' in locals()\n",
    "assert 'A2' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8328d956db92b07ad5df44a75a6d15d9",
     "grade": false,
     "grade_id": "cell-83371785b6191fa3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.14)** Run the function `generate_trajectories_classifier` to get the success rate of the learned planner over **100 environments** with **one obstacle** and save it in the variable `suc_5t`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#if you are stuck here, uncomment the lines below to load variables\n",
    "\n",
    "# In this case it is required to have pickle installed in the homl3 environment: pip install pickle-mixin\n",
    "\n",
    "# import pickle \n",
    "# with open('./get_unstuck/clf_fitted', 'rb') as config_dictionary_file:\n",
    "#    config_dictionary = pickle.load(config_dictionary_file) \n",
    "    \n",
    "# clf = config_dictionary['clf']\n",
    "# scaler = config_dictionary['scaler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "28ab92bd3a37001843cd8798c95fd4ff",
     "grade": false,
     "grade_id": "cell-e993e30a7b04f622",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "suc_5t = None  # MODIFY\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7a153d0bb7ef4de572087d8fa9199e42",
     "grade": true,
     "grade_id": "cell-634ea5a3b564bd34",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Please note: The expected outcome for the classifier should be better than 40%.\n",
    "assert suc_5t > 0.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bca4792031d63c338c82242eb390ce5b",
     "grade": false,
     "grade_id": "cell-c7c93c8e64a70aa9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.15)** The success rate of the classifier is low, which indicates that the learned planner will fail to reach of the goal more than half of the times. Taking into consideration **3.10**, what should we try to increase the performance of our planner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "30e7a70a403d6f77371948ac9798ce25",
     "grade": false,
     "grade_id": "cell-0633c272dc5ec726",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the correct answer\n",
    "\n",
    "#answer3 = 'a different learning algorithm'\n",
    "#answer3 = 'feature engineering'\n",
    "#answer3 = 'filter outliers'\n",
    "#answer3 = 'increase the size of the dataset'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5826e854c953264bdc2b969b71a94673",
     "grade": true,
     "grade_id": "cell-b196f150c053e406",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer3' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f7de5aa34eda8e843b509daa8b5794b7",
     "grade": false,
     "grade_id": "cell-9c0c51babcffa447",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3.16) Repeat experiment with different settings\n",
    "Using the functions the we created so far in this section, a new function can be constructed to run the complete experiment with different settings using as arguments `ds_n_obstacles`, `n_trajectories_dataset` and `n_trajectories_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5767df6a2c2d75268e35df22d82b52f5",
     "grade": false,
     "grade_id": "cell-3b6538a0f0d86630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def run_experiment(ds_n_obstacles, n_trajectories_dataset, n_trajectories_test, show=True):\n",
    "    # Create database\n",
    "    print('1) Create dataset: \\n')\n",
    "    states, actions = generate_dataset(ds_n_obstacles, n_trajectories_dataset, show=show)\n",
    "\n",
    "    # Train classifier\n",
    "    print('\\n2) Train classifier: \\n')\n",
    "    clf, accuracy, conf_matrix, scaler = train_classifier(states, actions)\n",
    "\n",
    "    # Generate trajectories with classifier\n",
    "    print('\\n3) Test classifier: \\n')\n",
    "    success_rate = generate_trajectories_classifier(clf, scaler, ds_n_obstacles, n_trajectories_test, show=show)\n",
    "    return success_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f1e5f2774003bca7a1846b9b64346bfa",
     "grade": false,
     "grade_id": "cell-14a437335748cdf3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.17)** Let's repeat the experiment with 20 trajectories in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe56ccbe30fa7e298eee2d28ae22141c",
     "grade": false,
     "grade_id": "cell-5f5c98fdda7a83f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "run_experiment(ds_n_obstacles=1, n_trajectories_dataset=20, n_trajectories_test=100, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b964e3aa2fc0217d1c994a6a11de119f",
     "grade": false,
     "grade_id": "cell-7e50e2782806e36f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.18)** The new planner B got an accuracy of 0.919 and a success rate of 0.97. The previous planner A got an accuracy of 0.938 and a success rate of 0.45. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9ff851b6bd8bb9eb8d54dda45cdaf2d",
     "grade": false,
     "grade_id": "cell-c9613ea58a5c441d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the correct answer\n",
    "\n",
    "#answer4 = 'A is slightly better because its accuracy is higher, but its success rate is lower'\n",
    "#answer4 = 'B is slightly better because its success rate is higher, but its accuracy is lower'\n",
    "#answer4 = 'A is clearly better because the accuracy better represents the performance of the planner'\n",
    "#answer4 = 'B is clearly better because the success rate better represents the performance of the planner'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b2fea02e70cab6a0d2d12f060b849255",
     "grade": true,
     "grade_id": "cell-3267ebf4790cc8df",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer4' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "91a752cc0e778710e6997c6bda337374",
     "grade": false,
     "grade_id": "cell-0a3cbe86b881e4e2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.19)** Therefore, can we conclude that increasing the size of the dataset helped to improve the performance of the learned planner? Choose the best answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "32a22c43b673c9ae4db720fbe072ba09",
     "grade": false,
     "grade_id": "cell-c16819e631ea623b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the correct answer\n",
    "\n",
    "#answer5 = 'yes, slightly'\n",
    "#answer5 = 'yes, a lot'\n",
    "#answer5 = 'it is not clear'\n",
    "#answer5 = 'no, it decreased'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1817a738fd89a53e1d9e3c9ff30faa8c",
     "grade": true,
     "grade_id": "cell-803c08a881d14967",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer5' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7e2b903920f585db8dbd21f6de0d736e",
     "grade": false,
     "grade_id": "cell-ac91ffd67d45fe8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3.20) Multiple Obstacles\n",
    "So far, we have been using environments with one obstacle, let's see what happens if we use environments with two obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "run_experiment(ds_n_obstacles=2, n_trajectories_dataset=20, n_trajectories_test=100, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f12757921e5cc55ea82a986dea0db457",
     "grade": false,
     "grade_id": "cell-141f7ba9482414a4",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.21)** The success rate decreased to 0.79 :(. What could be the most important reason? (*Hint:* this is an appetizer of chapter 8 in the book)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9fb7f73993d0bf766010662314e88d0",
     "grade": false,
     "grade_id": "cell-c7f537e39b82cb94",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Uncomment the correct answer\n",
    "\n",
    "#answer6 = 'there are many random variables that can influence the performance, so it is probably unluckiness'\n",
    "#answer6 = 'the curse of dimensionality'\n",
    "#answer6 = 'it is easier to collide if there are two obstacles'\n",
    "#answer6 = 'the problem became nonlinear'\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1421aa8f85e3343b5ab2047739644ac0",
     "grade": true,
     "grade_id": "cell-befcdba4e4e7f4cf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert 'answer6' in locals()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b60125bcf3805d5ea4903549fc30f403",
     "grade": false,
     "grade_id": "cell-ddf3c5547c099b91",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.22)** Once again, this problem can be alleviated with more data. Let's retrain using 100 trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0d85dfb12af3471296ec8ba210c7abe0",
     "grade": false,
     "grade_id": "cell-1c9d4c5d7e0cff27",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "run_experiment(ds_n_obstacles=2, n_trajectories_dataset=100, n_trajectories_test=100, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a0f0f6a82438bee1e48ce0adebc9c031",
     "grade": false,
     "grade_id": "cell-4dd6a70e3c8b0ae1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We can observe that the success rate increased to 0.89, which is not as good as before, but still is a good improvement :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "50974f143b790eb068cd046d9fb35ad4",
     "grade": false,
     "grade_id": "cell-66b82438a627311e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### 3.23) Repeat experiments with different settings and compare\n",
    "To finalize this assignment, we have the function `repeat_experiments` that gets the success rate of the classifier when trained with datasets of different sizes and different number of obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6f555bab25164dcb8490da5bb526141d",
     "grade": false,
     "grade_id": "cell-4c13fe757ea070f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def repeat_experiments(n_trajectories_list, n_obstacles_list):  \n",
    "    success_rate_list_obstacle = []\n",
    "    \n",
    "    # Iterate for every obstacle number\n",
    "    for i in n_obstacles_list:\n",
    "        print('\\nNumber of obstacles:', i)\n",
    "        success_rate_list_n_trajectories = []\n",
    "        \n",
    "        # Iterate for every number of trajectories in dataset\n",
    "        for j in n_trajectories_list:\n",
    "            print('\\nNumber trajectories dataset:', j)\n",
    "            \n",
    "            # Get success rate\n",
    "            suc_it = run_experiment(ds_n_obstacles=i, n_trajectories_dataset=j, n_trajectories_test=100, show=False)\n",
    "            success_rate_list_n_trajectories.append(suc_it)\n",
    "            \n",
    "        success_rate_list_obstacle.append(success_rate_list_n_trajectories)      \n",
    "    return success_rate_list_obstacle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "10882133dd3cc4c2c4d5b545904a03c8",
     "grade": false,
     "grade_id": "cell-cbc8e138fd6a4593",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.24)** Run it for 1, 2, and 3 obstacles, and for 1, 10, 20, 40, 60 and 80 demonstrations in our dataset.\n",
    "\n",
    "*Warning: it will take some time to get these results. It's a good opportunity to get a nice cup of tea...*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "62ac4e80b1b0b96e7594ccb265a645bb",
     "grade": false,
     "grade_id": "cell-382cf271be673977",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_trajectories_list = [1, 10, 20, 40, 60, 80, 100]\n",
    "n_obstacles_list = [1, 2, 3]\n",
    "success_rate_list = repeat_experiments(n_trajectories_list, n_obstacles_list=n_obstacles_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f58e37a1e154e46bbbaa515ccb4a3d1c",
     "grade": false,
     "grade_id": "cell-9b95a800be398249",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.25)** Let's plot these results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# Empty space for debugging your code if you are stuck. DO NOT REMOVE even if you don't end up using this space.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "#if you are stuck here, uncomment the lines below to load variables\n",
    "# npzfile = np.load('./get_unstuck/plot1.npz')\n",
    "# success_rate_list= npzfile['success_rate_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "eefd30d182e297591dbe0514f7e442d1",
     "grade": false,
     "grade_id": "cell-6884b9a05eb07a46",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "n_trajectories_list = [1, 10, 20, 40, 60, 80, 100]\n",
    "n_obstacles_list = [1, 2, 3]\n",
    "\n",
    "for i in range(len(n_obstacles_list)):\n",
    "    plt.plot(n_trajectories_list, success_rate_list[i], linestyle='--', linewidth=2, label=('%i obstacle(s)' % (i+1)))\n",
    "    plt.scatter(n_trajectories_list, success_rate_list[i], linewidth=3)\n",
    "    \n",
    "plt.grid('on')\n",
    "plt.xlabel('Number of trajectories in dataset')\n",
    "plt.ylabel('Success rate')\n",
    "plt.title('Influence of dataset size in success rate')\n",
    "plt.ylim(ymin=0)\n",
    "plt.xlim(xmin=0)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "51d2ae7eb87a5aeb9e0862566f1ee9cf",
     "grade": false,
     "grade_id": "cell-b8351318bdf43c5e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.26)** We can observe that increasing the dataset size will increase the performance of the classifier in environments with 1, 2, and 3 obstacles. This performance, however, seems to be bounded (and this bound gets lower as the number of obstacles increases), which suggests that adding more data will not be enough to completely solve this problem. Why do you think this is the case?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c2e76042240acbbaac222e81052e9e2c",
     "grade": false,
     "grade_id": "cell-339c01e898294c93",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**3.27)** In the motivation of this problem, we mentioned that Imitation Learning can be used to learn from humans. However, from this plot, we can observe that as the problem gets more complex (more obstacles in this case), more data is required to find good solutions. More data means more human time to generate the demonstrations, and human time is expensive.\n",
    "\n",
    "What limitations do you see in the approach that we used in this assignment to solve the motion planning problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "00c9300e75206683b54e3c4d1d317776",
     "grade": false,
     "grade_id": "cell-4e46ffd13ff55672",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That's it! Congratulations for reaching the end of this practicum :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
