{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AjYbZKDdI1mX"
      },
      "source": [
        "**Chapter 1 ‚Äì The Machine Learning landscape**\n",
        "\n",
        "_This notebook contains the code examples in chapter 1. You'll also find the exercise solutions at the end of the notebook. The rest of this notebook is used to generate `lifesat.csv` from the original data sources, and some of this chapter's figures._\n",
        "\n",
        "You're welcome to go through the code in this notebook if you want, but the real action starts in the next chapter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlIN7VRWI1mb"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td>\n",
        "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml3/blob/main/01_the_machine_learning_landscape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml3/blob/main/01_the_machine_learning_landscape.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "do6OP4SlI1mb"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rNku65pI1mc"
      },
      "source": [
        "This project requires Python 3.7 or above:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFjIyu7qI1mc"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "assert sys.version_info >= (3, 7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_E47vQ2xI1me"
      },
      "source": [
        "Scikit-Learn ‚â•1.0.1 is required:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lw0tq1hmI1me"
      },
      "outputs": [],
      "source": [
        "from packaging import version\n",
        "import sklearn\n",
        "\n",
        "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F78bB_gI1mf"
      },
      "source": [
        "Let's define the default font sizes, to plot pretty figures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_t8-jbfI1mf"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rc('font', size=12)\n",
        "plt.rc('axes', labelsize=14, titlesize=14)\n",
        "plt.rc('legend', fontsize=12)\n",
        "plt.rc('xtick', labelsize=10)\n",
        "plt.rc('ytick', labelsize=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Al35vP85I1mg"
      },
      "source": [
        "Make this notebook's output stable across runs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rczCARkAI1mg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpNoL7xwI1mh"
      },
      "source": [
        "# Code example 1-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1WVYCJTrI1mh"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Download and prepare the data\n",
        "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
        "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
        "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
        "y = lifesat[[\"Life satisfaction\"]].values\n",
        "\n",
        "# Visualize the data\n",
        "lifesat.plot(kind='scatter', grid=True,\n",
        "             x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
        "plt.axis([23_500, 62_500, 4, 9])\n",
        "plt.show()\n",
        "\n",
        "# Select a linear model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction for Cyprus\n",
        "X_new = [[37_655.2]]  # Cyprus' GDP per capita in 2020\n",
        "print(model.predict(X_new)) # outputs [[6.30165767]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilzFMWhPI1mi"
      },
      "source": [
        "Replacing the Linear Regression model with k-Nearest Neighbors (in this example, k = 3) regression in the previous code is as simple as replacing these two\n",
        "lines:\n",
        "\n",
        "```python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "```\n",
        "\n",
        "with these two:\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "46c0myZOI1mi"
      },
      "outputs": [],
      "source": [
        "# Select a 3-Nearest Neighbors regression model\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X, y)\n",
        "\n",
        "# Make a prediction for Cyprus\n",
        "print(model.predict(X_new)) # outputs [[6.33333333]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9m2b9YmSI1mj"
      },
      "source": [
        "# Generating the data and figures ‚Äî please skip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oD6_2QmI1mj"
      },
      "source": [
        "This is the code I used to generate the `lifesat.csv` dataset. You can safely skip this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mzl7ScU0I1mj"
      },
      "source": [
        "Create a function to save the figures:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4obUtAcI1mj"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "# Where to save the figures\n",
        "IMAGES_PATH = Path() / \"images\" / \"fundamentals\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = IMAGES_PATH / f\"{fig_id}.{fig_extension}\"\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_L2wL2yI1mk"
      },
      "source": [
        "## Load and prepare Life satisfaction data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rm5HRQHBI1mk"
      },
      "source": [
        "To create `lifesat.csv`, I downloaded the Better Life Index (BLI) data from [OECD's website](http://stats.oecd.org/index.aspx?DataSetCode=BLI) (to get the Life Satisfaction for each country), and World Bank GDP per capita data from [OurWorldInData.org](https://ourworldindata.org/grapher/gdp-per-capita-worldbank). The BLI data is in `datasets/lifesat/oecd_bli.csv` (data from 2020), and the GDP per capita data is in `datasets/lifesat/gdp_per_capita.csv` (data up to 2020).\n",
        "\n",
        "If you want to grab the latest versions, please feel free to do so. However, there may be some changes (e.g., in the column names, or different countries missing data), so be prepared to have to tweak the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmX-g3S5I1mk"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "\n",
        "datapath = Path() / \"datasets\" / \"lifesat\"\n",
        "datapath.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
        "for filename in (\"oecd_bli.csv\", \"gdp_per_capita.csv\"):\n",
        "    if not (datapath / filename).is_file():\n",
        "        print(\"Downloading\", filename)\n",
        "        url = data_root + \"lifesat/\" + filename\n",
        "        urllib.request.urlretrieve(url, datapath / filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoXTtY4oI1mk"
      },
      "outputs": [],
      "source": [
        "oecd_bli = pd.read_csv(datapath / \"oecd_bli.csv\")\n",
        "gdp_per_capita = pd.read_csv(datapath / \"gdp_per_capita.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtKHgRfmI1ml"
      },
      "source": [
        "Preprocess the GDP per capita data to keep only the year 2020:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Baf0vXYSI1ml"
      },
      "outputs": [],
      "source": [
        "gdp_year = 2020\n",
        "gdppc_col = \"GDP per capita (USD)\"\n",
        "lifesat_col = \"Life satisfaction\"\n",
        "\n",
        "gdp_per_capita = gdp_per_capita[gdp_per_capita[\"Year\"] == gdp_year]\n",
        "gdp_per_capita = gdp_per_capita.drop([\"Code\", \"Year\"], axis=1)\n",
        "gdp_per_capita.columns = [\"Country\", gdppc_col]\n",
        "gdp_per_capita.set_index(\"Country\", inplace=True)\n",
        "\n",
        "gdp_per_capita.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Imv9Six6I1ml"
      },
      "source": [
        "Preprocess the OECD BLI data to keep only the `Life satisfaction` column:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZnj2ndyI1ml"
      },
      "outputs": [],
      "source": [
        "oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
        "oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
        "\n",
        "oecd_bli.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zVuhONvI1mm"
      },
      "source": [
        "Now let's merge the life satisfaction data and the GDP per capita data, keeping only the GDP per capita and Life satisfaction columns:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PCg5B5HI1mm"
      },
      "outputs": [],
      "source": [
        "full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n",
        "                              left_index=True, right_index=True)\n",
        "full_country_stats.sort_values(by=gdppc_col, inplace=True)\n",
        "full_country_stats = full_country_stats[[gdppc_col, lifesat_col]]\n",
        "\n",
        "full_country_stats.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9tUrDklI1mm"
      },
      "source": [
        "To illustrate the risk of overfitting, I use only part of the data in most figures (all countries with a GDP per capita between `min_gdp` and `max_gdp`). Later in the chapter I reveal the missing countries, and show that they don't follow the same linear trend at all."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2oZY_13I1mn"
      },
      "outputs": [],
      "source": [
        "min_gdp = 23_500\n",
        "max_gdp = 62_500\n",
        "\n",
        "country_stats = full_country_stats[(full_country_stats[gdppc_col] >= min_gdp) &\n",
        "                                   (full_country_stats[gdppc_col] <= max_gdp)]\n",
        "country_stats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "177_nM3cI1mn"
      },
      "outputs": [],
      "source": [
        "country_stats.to_csv(datapath / \"lifesat.csv\")\n",
        "full_country_stats.to_csv(datapath / \"lifesat_full.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4grpbeKI1mn"
      },
      "outputs": [],
      "source": [
        "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
        "                   x=gdppc_col, y=lifesat_col)\n",
        "\n",
        "min_life_sat = 4\n",
        "max_life_sat = 9\n",
        "\n",
        "position_text = {\n",
        "    \"Turkey\": (29_500, 4.2),\n",
        "    \"Hungary\": (28_000, 6.9),\n",
        "    \"France\": (40_000, 5),\n",
        "    \"New Zealand\": (28_000, 8.2),\n",
        "    \"Australia\": (50_000, 5.5),\n",
        "    \"United States\": (59_000, 5.3),\n",
        "    \"Denmark\": (46_000, 8.5)\n",
        "}\n",
        "\n",
        "for country, pos_text in position_text.items():\n",
        "    pos_data_x = country_stats[gdppc_col].loc[country]\n",
        "    pos_data_y = country_stats[lifesat_col].loc[country]\n",
        "    country = \"U.S.\" if country == \"United States\" else country\n",
        "    plt.annotate(country, xy=(pos_data_x, pos_data_y),\n",
        "                 xytext=pos_text, fontsize=12,\n",
        "                 arrowprops=dict(facecolor='black', width=0.5,\n",
        "                                 shrink=0.08, headwidth=5))\n",
        "    plt.plot(pos_data_x, pos_data_y, \"ro\")\n",
        "\n",
        "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
        "\n",
        "save_fig('money_happy_scatterplot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b> ‚úÖAI Understanding Template-ML Landscape - 01 </b></summary>\n",
        "\n",
        "Below is a **short, crisp, AI-style explanation** using your requested template **+ a clear explanation of your full code**.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **AI Understanding Template ‚Äî Linear Regression + kNN Regression Code**\n",
        "\n",
        "## **1. What is it?**\n",
        "\n",
        "A small ML pipeline that:\n",
        "\n",
        "* Loads GDP & life-satisfaction data\n",
        "* Visualizes it\n",
        "* Trains **Linear Regression** and **k-Nearest Neighbors Regression**\n",
        "* Predicts Life Satisfaction for Cyprus\n",
        "* Saves plots & downloads OECD datasets\n",
        "* Cleans and merges datasets into a final CSV\n",
        "\n",
        "---\n",
        "\n",
        "## **2. How does it reason?**\n",
        "\n",
        "### **Linear Regression**\n",
        "\n",
        "* Fits a **straight line**:\n",
        "  [ y = aX + b ]\n",
        "* Predicts life satisfaction by projecting GDP onto that line.\n",
        "\n",
        "### **k-Nearest Neighbors (kNN)**\n",
        "\n",
        "* Finds the **3 closest GDP values** to Cyprus.\n",
        "* Averages their Life Satisfaction values.\n",
        "* More local, non-linear reasoning.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Where does it fail?**\n",
        "\n",
        "Linear Regression fails when:\n",
        "\n",
        "* Relationship is **non-linear**\n",
        "* Outliers distort the best-fit line\n",
        "\n",
        "kNN fails when:\n",
        "\n",
        "* Data is **sparse**\n",
        "* GDP neighbors are **not similar** socially/culturally\n",
        "* Wrong value of **k** chosen\n",
        "\n",
        "Both fail if:\n",
        "\n",
        "* Input GDP is **outside training range** (extrapolation).\n",
        "\n",
        "---\n",
        "\n",
        "## **4. When should I use it?**\n",
        "\n",
        "Use Linear Regression when:\n",
        "\n",
        "* Relationship is roughly **linear**\n",
        "* You want interpretability\n",
        "\n",
        "Use kNN when:\n",
        "\n",
        "* Relationship is **curved** or **local**\n",
        "* You want predictions based on **similar neighbours**\n",
        "\n",
        "---\n",
        "\n",
        "## **5. What is the mental model?**\n",
        "\n",
        "### Linear Regression\n",
        "\n",
        "> **‚ÄúDraw the best straight line through the points and read values from the line.‚Äù**\n",
        "\n",
        "### kNN\n",
        "\n",
        "> **‚ÄúFind 3 similar countries and average their happiness.‚Äù**\n",
        "\n",
        "---\n",
        "\n",
        "## **6. How do I prompt it?**\n",
        "\n",
        "(Not prompting AI ‚Äî but how to *use* the models.)\n",
        "\n",
        "* Give GDP values as a **2D array**:\n",
        "  `[[37655.2]]`\n",
        "* Fit the model with:\n",
        "  `model.fit(X, y)`\n",
        "* Predict with:\n",
        "  `model.predict(X_new)`\n",
        "* Keep GDP scaled or well-distributed if using kNN.\n",
        "\n",
        "---\n",
        "\n",
        "## **7. What are alternatives?**\n",
        "\n",
        "| Method                          | Why use it?                       |\n",
        "| ------------------------------- | --------------------------------- |\n",
        "| **Polynomial Regression**       | When curve fits better than line  |\n",
        "| **Random Forest Regression**    | Handles complex relations, robust |\n",
        "| **Gradient Boosting (XGBoost)** | High accuracy on tabular data     |\n",
        "| **Neural Networks**             | When dataset grows large          |\n",
        "| **LOESS/Smoothing**             | Non-parametric local regression   |\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **Code Explanation (Short & Clear)**\n",
        "\n",
        "---\n",
        "\n",
        "## **IMPORTS**\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "```\n",
        "\n",
        "* Loads libraries for charts, math, dataframes, and ML models.\n",
        "\n",
        "---\n",
        "\n",
        "## **LOAD DATA**\n",
        "\n",
        "```python\n",
        "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
        "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
        "```\n",
        "\n",
        "* Downloads pre-cleaned GDP + life satisfaction dataset.\n",
        "\n",
        "### Split columns:\n",
        "\n",
        "```python\n",
        "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
        "y = lifesat[[\"Life satisfaction\"]].values\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **VISUALIZE**\n",
        "\n",
        "```python\n",
        "lifesat.plot(kind='scatter', grid=True, x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
        "plt.axis([23500, 62500, 4, 9])\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "* Scatter plot to see the relationship.\n",
        "\n",
        "---\n",
        "\n",
        "## **LINEAR MODEL**\n",
        "\n",
        "```python\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "* Fits a straight-line model.\n",
        "\n",
        "### Predict Cyprus:\n",
        "\n",
        "```python\n",
        "X_new = [[37655.2]]\n",
        "print(model.predict(X_new))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **KNN MODEL (3 neighbors)**\n",
        "\n",
        "```python\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "model.fit(X, y)\n",
        "print(model.predict(X_new))\n",
        "```\n",
        "\n",
        "* Predicts using 3 nearest GDP values.\n",
        "\n",
        "---\n",
        "\n",
        "## **SAVE FIGURES**\n",
        "\n",
        "```python\n",
        "IMAGES_PATH = Path() / \"images\" / \"fundamentals\"\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "```\n",
        "\n",
        "* Prepares folder for saving images.\n",
        "\n",
        "### Save function:\n",
        "\n",
        "```python\n",
        "def save_fig(...):\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(path, dpi=300)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **DOWNLOAD RAW DATA**\n",
        "\n",
        "```python\n",
        "for filename in (\"oecd_bli.csv\", \"gdp_per_capita.csv\"):\n",
        "    urllib.request.urlretrieve(url, datapath / filename)\n",
        "```\n",
        "\n",
        "* Downloads two datasets from OECD.\n",
        "\n",
        "---\n",
        "\n",
        "## **CLEAN AND PREPARE DATA**\n",
        "\n",
        "```python\n",
        "gdp_per_capita = gdp_per_capita[gdp_per_capita[\"Year\"] == gdp_year]\n",
        "gdp_per_capita.drop([\"Code\",\"Year\"], axis=1)\n",
        "...\n",
        "```\n",
        "\n",
        "* Filters for year 2020\n",
        "* Renames columns\n",
        "* Sets country as index\n",
        "\n",
        "---\n",
        "\n",
        "## **PIVOT LIFE SATISFACTION (OECD data)**\n",
        "\n",
        "```python\n",
        "oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n",
        "oecd_bli = oecd_bli.pivot(...)\n",
        "```\n",
        "\n",
        "* Removes inequality variations\n",
        "* Turns indicators into columns\n",
        "\n",
        "---\n",
        "\n",
        "## **MERGE BOTH DATASETS**\n",
        "\n",
        "```python\n",
        "full_country_stats = pd.merge(...)\n",
        "full_country_stats.sort_values(...)\n",
        "```\n",
        "\n",
        "* Combine happiness + GDP into one table\n",
        "* Sort by GDP\n",
        "\n",
        "---\n",
        "\n",
        "## **FILTER GDP RANGE**\n",
        "\n",
        "```python\n",
        "country_stats = full_country_stats[(...)]\n",
        "```\n",
        "\n",
        "* Keeps values between 23.5k and 62.5k USD.\n",
        "\n",
        "---\n",
        "\n",
        "## **SAVE AS CSV**\n",
        "\n",
        "```python\n",
        "country_stats.to_csv(...)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **ANNOTATE COUNTRIES ON PLOT**\n",
        "\n",
        "Uses:\n",
        "\n",
        "```python\n",
        "plt.annotate(...)\n",
        "```\n",
        "\n",
        "* Adds labels + arrows for selected countries\n",
        "* Helps visualize outliers and unique positions.\n",
        "\n",
        "---\n",
        "\n",
        "## **FINAL PLOT + SAVE**\n",
        "\n",
        "```python\n",
        "save_fig('money_happy_scatterplot')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# If you want\n",
        "\n",
        "I can also give you:\n",
        "\n",
        "‚úî 20-word summary\n",
        "‚úî Conceptual diagram\n",
        "‚úî Same explanation in ‚Äúinterview answer‚Äù style\n",
        "‚úî Equivalent code using **Polynomial Regression** or **Random Forest**\n",
        "\n",
        "\n",
        "<details>"
      ],
      "metadata": {
        "id": "gS0YolP-LEdq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b> ‚úÖAI Understanding Template-ML landscape -01 - CheatSheet and QnA </b></summary>\n",
        "#1 - Cheatsheet\n",
        "\n",
        "Here is a **short, crisp, high-value Cheat Sheet** for your entire Life Satisfaction (GDP ‚Üí Happiness) code pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "# üß≠ **Life Satisfaction ML Pipeline ‚Äî Cheat Sheet (Super-Short)**\n",
        "\n",
        "---\n",
        "\n",
        "## **1. Imports**\n",
        "\n",
        "```python\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from pathlib import Path\n",
        "import urllib.request\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üì• **2. Load Dataset**\n",
        "\n",
        "```python\n",
        "data_root = \"https://github.com/ageron/data/raw/main/\"\n",
        "lifesat = pd.read_csv(data_root + \"lifesat/lifesat.csv\")\n",
        "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
        "y = lifesat[[\"Life satisfaction\"]].values\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üìä **3. Visualize Relationship**\n",
        "\n",
        "```python\n",
        "lifesat.plot(kind='scatter', grid=True,\n",
        "             x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
        "plt.axis([23500, 62500, 4, 9])\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ü§ñ **4. Train Models**\n",
        "\n",
        "### **Linear Regression**\n",
        "\n",
        "```python\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "### **kNN Regression (k=3)**\n",
        "\n",
        "```python\n",
        "model = KNeighborsRegressor(n_neighbors=3)\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üìå **5. Predict for Cyprus**\n",
        "\n",
        "```python\n",
        "X_new = [[37655.2]]\n",
        "model.predict(X_new)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üíæ **6. Save Figures**\n",
        "\n",
        "```python\n",
        "IMAGES_PATH = Path(\"images/fundamentals\")\n",
        "IMAGES_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def save_fig(id):\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(IMAGES_PATH / f\"{id}.png\", dpi=300)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üîΩ **7. Download Raw OECD Datasets**\n",
        "\n",
        "```python\n",
        "datapath = Path(\"datasets/lifesat\")\n",
        "datapath.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "for file in (\"oecd_bli.csv\", \"gdp_per_capita.csv\"):\n",
        "    url = data_root + \"lifesat/\" + file\n",
        "    urllib.request.urlretrieve(url, datapath / file)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üßπ **8. Prepare GDP Dataset**\n",
        "\n",
        "```python\n",
        "gdp = pd.read_csv(datapath / \"gdp_per_capita.csv\")\n",
        "gdp = gdp[gdp[\"Year\"] == 2020]\n",
        "gdp = gdp.drop([\"Code\", \"Year\"], axis=1)\n",
        "gdp.columns = [\"Country\", \"GDP per capita (USD)\"]\n",
        "gdp.set_index(\"Country\", inplace=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üßπ **9. Prepare Life Satisfaction Dataset**\n",
        "\n",
        "```python\n",
        "bli = pd.read_csv(datapath / \"oecd_bli.csv\")\n",
        "bli = bli[bli[\"INEQUALITY\"] == \"TOT\"]\n",
        "bli = bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üîó **10. Merge Both Datasets**\n",
        "\n",
        "```python\n",
        "full_stats = pd.merge(bli, gdp, left_index=True, right_index=True)\n",
        "full_stats.sort_values(by=\"GDP per capita (USD)\", inplace=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ü™ú **11. Filter GDP Range**\n",
        "\n",
        "```python\n",
        "min_gdp, max_gdp = 23500, 62500\n",
        "stats = full_stats[(full_stats[\"GDP per capita (USD)\"] >= min_gdp) &\n",
        "                   (full_stats[\"GDP per capita (USD)\"] <= max_gdp)]\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üíæ **12. Save Cleaned CSV**\n",
        "\n",
        "```python\n",
        "stats.to_csv(datapath / \"lifesat.csv\")\n",
        "full_stats.to_csv(datapath / \"lifesat_full.csv\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üñäÔ∏è **13. Annotate Countries on Plot**\n",
        "\n",
        "```python\n",
        "for country, text_pos in position_text.items():\n",
        "    x = stats.loc[country][\"GDP per capita (USD)\"]\n",
        "    y = stats.loc[country][\"Life satisfaction\"]\n",
        "    plt.annotate(country, xy=(x, y), xytext=text_pos,\n",
        "                 arrowprops=dict(facecolor=\"black\"))\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üìà **14. Final Visualization**\n",
        "\n",
        "```python\n",
        "plt.axis([23500, 62500, 4, 9])\n",
        "save_fig(\"money_happy_scatterplot\")\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê **Ultra-Fast Summary (For Revision)**\n",
        "\n",
        "### ‚úî Load ‚Üí Visualize ‚Üí Train (Linear + kNN) ‚Üí Predict\n",
        "\n",
        "### ‚úî Download OECD data ‚Üí Clean ‚Üí Merge ‚Üí Filter ‚Üí Save\n",
        "\n",
        "### ‚úî Plot + Annotate ‚Üí Export figure\n",
        "\n",
        "---\n",
        "\n",
        "If you want, I can also give you:\n",
        "\n",
        "üìå A **one-page PDF cheat sheet**\n",
        "üìå A **side-by-side comparison of Linear Regression vs kNN**\n",
        "üìå A **flow diagram of the entire pipeline**\n",
        "\n",
        "\n",
        "\n",
        "#2 -\n",
        "\n",
        "Here is a **short, crisp, interview-style Q&A summary** of your entire Life Satisfaction ML code.\n",
        "\n",
        "---\n",
        "\n",
        "# üîç **Interview-Style Q&A Summary ‚Äî Life Satisfaction ML Pipeline**\n",
        "\n",
        "---\n",
        "\n",
        "### **1. What problem is this code solving?**\n",
        "\n",
        "It predicts **Life Satisfaction** of a country using **GDP per capita**.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. What data is being used?**\n",
        "\n",
        "OECD datasets containing:\n",
        "\n",
        "* **GDP per capita**\n",
        "* **Life satisfaction scores**\n",
        "\n",
        "---\n",
        "\n",
        "### **3. How is the data loaded?**\n",
        "\n",
        "```python\n",
        "pd.read_csv(\"...lifesat.csv\")\n",
        "```\n",
        "\n",
        "Or downloaded directly from GitHub using `urllib.request`.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. How are features and labels defined?**\n",
        "\n",
        "* **X** = GDP per capita\n",
        "* **y** = Life satisfaction\n",
        "\n",
        "```python\n",
        "X = lifesat[[\"GDP per capita (USD)\"]].values\n",
        "y = lifesat[[\"Life satisfaction\"]].values\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **5. How is the relationship visualized?**\n",
        "\n",
        "A scatterplot to inspect linearity:\n",
        "\n",
        "```python\n",
        "lifesat.plot(kind='scatter', x=\"GDP per capita (USD)\", y=\"Life satisfaction\")\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **6. What ML models are used?**\n",
        "\n",
        "Two models:\n",
        "\n",
        "1. **Linear Regression** (assumes straight-line relationship)\n",
        "2. **k-Nearest Neighbors Regressor (k=3)** (non-linear, local averaging)\n",
        "\n",
        "---\n",
        "\n",
        "### **7. How are models trained?**\n",
        "\n",
        "```python\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **8. What is the prediction example?**\n",
        "\n",
        "Predict Life Satisfaction for Cyprus using GDP `37655.2`.\n",
        "\n",
        "* Linear Regression ‚Üí ~6.30\n",
        "* kNN (k=3) ‚Üí ~6.33\n",
        "\n",
        "---\n",
        "\n",
        "### **9. Why try two models?**\n",
        "\n",
        "To compare:\n",
        "\n",
        "* **Global linear trend** vs\n",
        "* **Local neighbor-based prediction**\n",
        "\n",
        "---\n",
        "\n",
        "### **10. Why restrict GDP range?**\n",
        "\n",
        "To remove outliers that distort regression.\n",
        "\n",
        "```python\n",
        "min_gdp, max_gdp = 23500, 62500\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **11. How are the datasets merged?**\n",
        "\n",
        "Using country index:\n",
        "\n",
        "```python\n",
        "pd.merge(oecd_bli, gdp_per_capita, left_index=True, right_index=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **12. Why pivot OECD_BLI?**\n",
        "\n",
        "To turn indicators into columns ‚Üí clean country-level table.\n",
        "\n",
        "---\n",
        "\n",
        "### **13. What is saved in the end?**\n",
        "\n",
        "* `lifesat.csv` ‚Üí filtered dataset\n",
        "* `lifesat_full.csv` ‚Üí full merged dataset\n",
        "* `money_happy_scatterplot.png` ‚Üí annotated plot\n",
        "\n",
        "---\n",
        "\n",
        "### **14. How are the annotated visuals created?**\n",
        "\n",
        "Using:\n",
        "\n",
        "```python\n",
        "plt.annotate(...)\n",
        "plt.plot(...)\n",
        "```\n",
        "\n",
        "for each selected country.\n",
        "\n",
        "---\n",
        "\n",
        "### **15. What is the final output?**\n",
        "\n",
        "A clean ML pipeline that:\n",
        "‚úî Downloads ‚Üí cleans ‚Üí merges ‚Üí visualizes data\n",
        "‚úî Trains Linear + kNN models\n",
        "‚úî Predicts life satisfaction for new GDP values\n",
        "‚úî Saves cleaned data + images\n",
        "\n",
        "---\n",
        "\n",
        "If you want, I can also create:\n",
        "üìå **10 interview questions based on this code**\n",
        "üìå **A one-page revision sheet**\n",
        "üìå **A diagram of the entire pipeline**\n",
        "\n",
        "------------------------------\n",
        "#3 - 20 interview questions\n",
        "Here are **20 crisp, interview-style questions** based on your Life Satisfaction (GDP ‚Üí Happiness) ML code:\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **20 Interview Questions Based on the Code**\n",
        "\n",
        "### **1. What is the primary prediction goal of this ML pipeline?**\n",
        "\n",
        "To predict *Life Satisfaction* from *GDP per capita*.\n",
        "\n",
        "---\n",
        "\n",
        "### **2. How do you load a CSV file from a URL in Python?**\n",
        "\n",
        "Using `pd.read_csv(url)` or `urllib.request.urlretrieve`.\n",
        "\n",
        "---\n",
        "\n",
        "### **3. Why do we convert pandas columns to `.values`?**\n",
        "\n",
        "Because scikit-learn models expect **NumPy arrays**, not DataFrames.\n",
        "\n",
        "---\n",
        "\n",
        "### **4. Why is a scatterplot used before training the model?**\n",
        "\n",
        "To visually inspect if a **linear relationship** exists between variables.\n",
        "\n",
        "---\n",
        "\n",
        "### **5. What assumptions does Linear Regression make in this context?**\n",
        "\n",
        "It assumes a **straight-line** relationship between GDP and life satisfaction.\n",
        "\n",
        "---\n",
        "\n",
        "### **6. When would k-Nearest Neighbors outperform Linear Regression?**\n",
        "\n",
        "When the relationship is **non-linear** and **locally varying**.\n",
        "\n",
        "---\n",
        "\n",
        "### **7. How do you choose the value of k in KNN?**\n",
        "\n",
        "Through **cross-validation** or empirical testing.\n",
        "\n",
        "---\n",
        "\n",
        "### **8. Why do we filter GDP between 23,500 and 62,500?**\n",
        "\n",
        "To remove **outliers** that distort linear model fitting.\n",
        "\n",
        "---\n",
        "\n",
        "### **9. What does `pivot()` achieve in the OECD_BLI dataset?**\n",
        "\n",
        "It transforms **indicators into separate columns**, creating a tidy table.\n",
        "\n",
        "---\n",
        "\n",
        "### **10. How do you merge two datasets on country?**\n",
        "\n",
        "Using:\n",
        "\n",
        "```python\n",
        "pd.merge(left, right, left_index=True, right_index=True)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "### **11. Why do we use `.set_index(\"Country\")` for GDP data?**\n",
        "\n",
        "To match the index of OECD data for merging.\n",
        "\n",
        "---\n",
        "\n",
        "### **12. What is the significance of annotating points on the scatterplot?**\n",
        "\n",
        "To highlight specific countries with unique GDP‚ÄìLife Satisfaction positions.\n",
        "\n",
        "---\n",
        "\n",
        "### **13. What does `plt.axis([..])` do?**\n",
        "\n",
        "Sets **manual limits** for x and y axes for consistent visualization.\n",
        "\n",
        "---\n",
        "\n",
        "### **14. Why do we save the cleaned datasets (`lifesat.csv` and full CSV`)?**\n",
        "\n",
        "For **reuse**, **reproducibility**, and to avoid re-downloading.\n",
        "\n",
        "---\n",
        "\n",
        "### **15. What is the purpose of `save_fig()`?**\n",
        "\n",
        "To export plots with consistent settings (layout, dpi, path).\n",
        "\n",
        "---\n",
        "\n",
        "### **16. Why is `model.predict()` called with a 2D array?**\n",
        "\n",
        "Because scikit-learn expects inputs shaped as **(n_samples, n_features)**.\n",
        "\n",
        "---\n",
        "\n",
        "### **17. What happens if Cyprus‚Äô GDP value is passed as a 1D list?**\n",
        "\n",
        "It would raise a shape error; must be wrapped as `[[value]]`.\n",
        "\n",
        "---\n",
        "\n",
        "### **18. How does Linear Regression compute predictions?**\n",
        "\n",
        "Using:\n",
        "\n",
        "```\n",
        "y = b0 + b1 * x\n",
        "```\n",
        "\n",
        "after estimating optimal coefficients via **least squares**.\n",
        "\n",
        "---\n",
        "\n",
        "### **19. How does kNN compute predictions?**\n",
        "\n",
        "It finds the **k nearest GDP values** and returns the **average Life Satisfaction**.\n",
        "\n",
        "---\n",
        "\n",
        "### **20. Why export the final annotated figure?**\n",
        "\n",
        "For **reports**, **publications**, and **visual storytelling** in analysis.\n",
        "\n",
        "---\n",
        "\n",
        "If you want, I can also create:\n",
        "\n",
        "üìå **20 MCQs based on this code**\n",
        "üìå **20 coding interview tasks from this pipeline**\n",
        "üìå **A ready-to-use interview notes PDF**\n",
        "\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "gEPoW8vYSsWd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMhB-oPdI1mo"
      },
      "outputs": [],
      "source": [
        "highlighted_countries = country_stats.loc[list(position_text.keys())]\n",
        "highlighted_countries[[gdppc_col, lifesat_col]].sort_values(by=gdppc_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vj3CXqZfI1mp"
      },
      "outputs": [],
      "source": [
        "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
        "                   x=gdppc_col, y=lifesat_col)\n",
        "\n",
        "X = np.linspace(min_gdp, max_gdp, 1000)\n",
        "\n",
        "w1, w2 = 4.2, 0\n",
        "plt.plot(X, w1 + w2 * 1e-5 * X, \"r\")\n",
        "plt.text(40_000, 4.9, fr\"$\\theta_0 = {w1}$\", color=\"r\")\n",
        "plt.text(40_000, 4.4, fr\"$\\theta_1 = {w2}$\", color=\"r\")\n",
        "\n",
        "w1, w2 = 10, -9\n",
        "plt.plot(X, w1 + w2 * 1e-5 * X, \"g\")\n",
        "plt.text(26_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"g\")\n",
        "plt.text(26_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"g\")\n",
        "\n",
        "w1, w2 = 3, 8\n",
        "plt.plot(X, w1 + w2 * 1e-5 * X, \"b\")\n",
        "plt.text(48_000, 8.5, fr\"$\\theta_0 = {w1}$\", color=\"b\")\n",
        "plt.text(48_000, 8.0, fr\"$\\theta_1 = {w2} \\times 10^{{-5}}$\", color=\"b\")\n",
        "\n",
        "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
        "\n",
        "save_fig('tweaking_model_params_plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDFRJ2gmI1mp"
      },
      "outputs": [],
      "source": [
        "from sklearn import linear_model\n",
        "\n",
        "X_sample = country_stats[[gdppc_col]].values\n",
        "y_sample = country_stats[[lifesat_col]].values\n",
        "\n",
        "lin1 = linear_model.LinearRegression()\n",
        "lin1.fit(X_sample, y_sample)\n",
        "\n",
        "t0, t1 = lin1.intercept_[0], lin1.coef_.ravel()[0]\n",
        "print(f\"Œ∏0={t0:.2f}, Œ∏1={t1:.2e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gsAxlWsI1mq"
      },
      "outputs": [],
      "source": [
        "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
        "                   x=gdppc_col, y=lifesat_col)\n",
        "\n",
        "X = np.linspace(min_gdp, max_gdp, 1000)\n",
        "plt.plot(X, t0 + t1 * X, \"b\")\n",
        "\n",
        "plt.text(max_gdp - 20_000, min_life_sat + 1.9,\n",
        "         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\n",
        "plt.text(max_gdp - 20_000, min_life_sat + 1.3,\n",
        "         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n",
        "\n",
        "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
        "\n",
        "save_fig('best_fit_model_plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-_8FNBkI1mq"
      },
      "outputs": [],
      "source": [
        "cyprus_gdp_per_capita = gdp_per_capita[gdppc_col].loc[\"Cyprus\"]\n",
        "cyprus_gdp_per_capita"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cJAWTy-FI1mq"
      },
      "outputs": [],
      "source": [
        "cyprus_predicted_life_satisfaction = lin1.predict([[cyprus_gdp_per_capita]])[0, 0]\n",
        "cyprus_predicted_life_satisfaction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJHoJ-FbI1m8"
      },
      "outputs": [],
      "source": [
        "country_stats.plot(kind='scatter', figsize=(5, 3), grid=True,\n",
        "                   x=gdppc_col, y=lifesat_col)\n",
        "\n",
        "X = np.linspace(min_gdp, max_gdp, 1000)\n",
        "plt.plot(X, t0 + t1 * X, \"b\")\n",
        "\n",
        "plt.text(min_gdp + 22_000, max_life_sat - 1.1,\n",
        "         fr\"$\\theta_0 = {t0:.2f}$\", color=\"b\")\n",
        "plt.text(min_gdp + 22_000, max_life_sat - 0.6,\n",
        "         fr\"$\\theta_1 = {t1 * 1e5:.2f} \\times 10^{{-5}}$\", color=\"b\")\n",
        "\n",
        "plt.plot([cyprus_gdp_per_capita, cyprus_gdp_per_capita],\n",
        "         [min_life_sat, cyprus_predicted_life_satisfaction], \"r--\")\n",
        "plt.text(cyprus_gdp_per_capita + 1000, 5.0,\n",
        "         fr\"Prediction = {cyprus_predicted_life_satisfaction:.2f}\", color=\"r\")\n",
        "plt.plot(cyprus_gdp_per_capita, cyprus_predicted_life_satisfaction, \"ro\")\n",
        "\n",
        "plt.axis([min_gdp, max_gdp, min_life_sat, max_life_sat])\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C7c_3BRoI1m8"
      },
      "outputs": [],
      "source": [
        "missing_data = full_country_stats[(full_country_stats[gdppc_col] < min_gdp) |\n",
        "                                  (full_country_stats[gdppc_col] > max_gdp)]\n",
        "missing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fhGbOf_I1m9"
      },
      "outputs": [],
      "source": [
        "position_text_missing_countries = {\n",
        "    \"South Africa\": (20_000, 4.2),\n",
        "    \"Colombia\": (6_000, 8.2),\n",
        "    \"Brazil\": (18_000, 7.8),\n",
        "    \"Mexico\": (24_000, 7.4),\n",
        "    \"Chile\": (30_000, 7.0),\n",
        "    \"Norway\": (51_000, 6.2),\n",
        "    \"Switzerland\": (62_000, 5.7),\n",
        "    \"Ireland\": (81_000, 5.2),\n",
        "    \"Luxembourg\": (92_000, 4.7),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGxJMDtBI1m9"
      },
      "outputs": [],
      "source": [
        "full_country_stats.plot(kind='scatter', figsize=(8, 3),\n",
        "                        x=gdppc_col, y=lifesat_col, grid=True)\n",
        "\n",
        "for country, pos_text in position_text_missing_countries.items():\n",
        "    pos_data_x, pos_data_y = missing_data.loc[country]\n",
        "    plt.annotate(country, xy=(pos_data_x, pos_data_y),\n",
        "                 xytext=pos_text, fontsize=12,\n",
        "                 arrowprops=dict(facecolor='black', width=0.5,\n",
        "                                 shrink=0.08, headwidth=5))\n",
        "    plt.plot(pos_data_x, pos_data_y, \"rs\")\n",
        "\n",
        "X = np.linspace(0, 115_000, 1000)\n",
        "plt.plot(X, t0 + t1 * X, \"b:\")\n",
        "\n",
        "lin_reg_full = linear_model.LinearRegression()\n",
        "Xfull = np.c_[full_country_stats[gdppc_col]]\n",
        "yfull = np.c_[full_country_stats[lifesat_col]]\n",
        "lin_reg_full.fit(Xfull, yfull)\n",
        "\n",
        "t0full, t1full = lin_reg_full.intercept_[0], lin_reg_full.coef_.ravel()[0]\n",
        "X = np.linspace(0, 115_000, 1000)\n",
        "plt.plot(X, t0full + t1full * X, \"k\")\n",
        "\n",
        "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
        "\n",
        "save_fig('representative_training_data_scatterplot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xSzxlNWxI1m9"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "from sklearn import pipeline\n",
        "\n",
        "full_country_stats.plot(kind='scatter', figsize=(8, 3),\n",
        "                        x=gdppc_col, y=lifesat_col, grid=True)\n",
        "\n",
        "poly = preprocessing.PolynomialFeatures(degree=10, include_bias=False)\n",
        "scaler = preprocessing.StandardScaler()\n",
        "lin_reg2 = linear_model.LinearRegression()\n",
        "\n",
        "pipeline_reg = pipeline.Pipeline([\n",
        "    ('poly', poly),\n",
        "    ('scal', scaler),\n",
        "    ('lin', lin_reg2)])\n",
        "pipeline_reg.fit(Xfull, yfull)\n",
        "curve = pipeline_reg.predict(X[:, np.newaxis])\n",
        "plt.plot(X, curve)\n",
        "\n",
        "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
        "\n",
        "save_fig('overfitting_model_plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61mrhtKHI1m-"
      },
      "outputs": [],
      "source": [
        "w_countries = [c for c in full_country_stats.index if \"W\" in c.upper()]\n",
        "full_country_stats.loc[w_countries][lifesat_col]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gFfRS3MwI1m-"
      },
      "outputs": [],
      "source": [
        "all_w_countries = [c for c in gdp_per_capita.index if \"W\" in c.upper()]\n",
        "gdp_per_capita.loc[all_w_countries].sort_values(by=gdppc_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iEQCpyS-I1m-"
      },
      "outputs": [],
      "source": [
        "country_stats.plot(kind='scatter', x=gdppc_col, y=lifesat_col, figsize=(8, 3))\n",
        "missing_data.plot(kind='scatter', x=gdppc_col, y=lifesat_col,\n",
        "                  marker=\"s\", color=\"r\", grid=True, ax=plt.gca())\n",
        "\n",
        "X = np.linspace(0, 115_000, 1000)\n",
        "plt.plot(X, t0 + t1*X, \"b:\", label=\"Linear model on partial data\")\n",
        "plt.plot(X, t0full + t1full * X, \"k-\", label=\"Linear model on all data\")\n",
        "\n",
        "ridge = linear_model.Ridge(alpha=10**9.5)\n",
        "X_sample = country_stats[[gdppc_col]]\n",
        "y_sample = country_stats[[lifesat_col]]\n",
        "ridge.fit(X_sample, y_sample)\n",
        "t0ridge, t1ridge = ridge.intercept_[0], ridge.coef_.ravel()[0]\n",
        "plt.plot(X, t0ridge + t1ridge * X, \"b--\",\n",
        "         label=\"Regularized linear model on partial data\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.axis([0, 115_000, min_life_sat, max_life_sat])\n",
        "\n",
        "save_fig('ridge_model_plot')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b> ‚úÖAI Understanding Template-01-ML Landscape -02 </b></summary>\n",
        "Below is a **short, crisp, high-signal AI-style explanation** for your entire code.\n",
        "This includes:\n",
        "\n",
        "‚úî The 7-point AI template\n",
        "‚úî Clear explanation of **what the code is doing step-by-step**\n",
        "‚úî Why each model/version is used\n",
        "‚úî Failures, mental model, prompting, alternatives\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **AI Understanding Template (Applied to Your Linear Regression Code)**\n",
        "\n",
        "## **1. What is it?**\n",
        "\n",
        "A complete workflow demonstrating **linear regression on tabular data**, including:\n",
        "\n",
        "* Selecting/trimming data\n",
        "* Plotting data\n",
        "* Visualizing manually-chosen model lines\n",
        "* Fitting the best linear model\n",
        "* Predicting for a new country\n",
        "* Showing missing/out-of-range data\n",
        "* Showing overfitting via polynomial regression\n",
        "* Showing regularization via Ridge regression\n",
        "\n",
        "---\n",
        "\n",
        "## **2. How does it reason?**\n",
        "\n",
        "The model learns:\n",
        "\n",
        "> **Life satisfaction = Œ∏0 + Œ∏1 √ó GDP_per_capita**\n",
        "\n",
        "It finds Œ∏0 and Œ∏1 by minimizing the **mean squared error** between predicted and real life satisfaction.\n",
        "\n",
        "The later polynomial model learns:\n",
        "\n",
        "> **Life satisfaction = a0 + a1x + a2x¬≤ + ‚Ä¶ + a10x¬π‚Å∞**\n",
        "\n",
        "The Ridge model reasons by:\n",
        "\n",
        "> ‚ÄúFit the data but keep coefficients small to avoid overfitting.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Where does it fail?**\n",
        "\n",
        "* GDP ‚Üí Life Satisfaction is **not truly linear**.\n",
        "* Missing countries (e.g., South Africa, Switzerland) distort predictions.\n",
        "* Polynomial model **overfits** (wild curves).\n",
        "* Partial-data linear model is biased.\n",
        "* Real-world happiness depends on **many features**, not just GDP.\n",
        "\n",
        "---\n",
        "\n",
        "## **4. When should I use it?**\n",
        "\n",
        "Use this approach when:\n",
        "\n",
        "* Relationship looks roughly linear.\n",
        "* You need a **fast, interpretable** model.\n",
        "* You want a baseline before deeper models.\n",
        "* You need a full teaching pipeline: plots ‚Üí linear ‚Üí polynomial ‚Üí Ridge.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Mental model**\n",
        "\n",
        "Think of it as:\n",
        "\n",
        "> **Drawing the best straight line through scattered points, then experimenting with curved lines and regularization.**\n",
        "\n",
        "---\n",
        "\n",
        "## **6. How do I prompt it?**\n",
        "\n",
        "(In code terms)\n",
        "\n",
        "* Input X must be **2D** (GDP column).\n",
        "* Input y must be **2D** (LifeSat column).\n",
        "* Fit using `.fit(X, y)`\n",
        "* Predict using `.predict([[new_value]])`\n",
        "* Visualize with `plt.plot()` and `DataFrame.plot()`\n",
        "* Add text with `plt.text()`\n",
        "* Annotate missing data with `plt.annotate()`\n",
        "\n",
        "---\n",
        "\n",
        "## **7. Alternatives**\n",
        "\n",
        "| Model                             | When to use                             |\n",
        "| --------------------------------- | --------------------------------------- |\n",
        "| **LinearRegression**              | Relationship is simple & linear         |\n",
        "| **Polynomial + LinearRegression** | Need non-linear curve fit               |\n",
        "| **Ridge/Lasso/ElasticNet**        | Need stable model + prevent overfitting |\n",
        "| **RandomForestRegressor**         | Tabular + non-linear without math       |\n",
        "| **XGBoost/CatBoost**              | State-of-the-art tabular performance    |\n",
        "| **Neural Networks**               | Large dataset, complex patterns         |\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **Code Explanation (Short, Direct, Step-by-Step)**\n",
        "\n",
        "### **1) Highlight selected countries**\n",
        "\n",
        "```python\n",
        "highlighted_countries = country_stats.loc[list(position_text.keys())]\n",
        "highlighted_countries[[gdppc_col, lifesat_col]].sort_values(by=gdppc_col)\n",
        "```\n",
        "\n",
        "You pick a set of countries, extract their rows, and sort by GDP per capita.\n",
        "\n",
        "---\n",
        "\n",
        "### **2) Plot the original data**\n",
        "\n",
        "```python\n",
        "country_stats.plot(kind='scatter', x=gdppc_col, y=lifesat_col)\n",
        "```\n",
        "\n",
        "Shows the raw GDP-vs-LifeSatisfaction scatterplot.\n",
        "\n",
        "---\n",
        "\n",
        "### **3) Plot hand-selected linear models**\n",
        "\n",
        "Each block:\n",
        "\n",
        "```python\n",
        "w1, w2 = 4.2, 0\n",
        "plt.plot(X, w1 + w2 * 1e-5 * X, \"r\")\n",
        "```\n",
        "\n",
        "You manually draw 3 different trial lines to see:\n",
        "\n",
        "* Red line\n",
        "* Green line\n",
        "* Blue line\n",
        "\n",
        "These are *guesses for Œ∏0, Œ∏1*.\n",
        "\n",
        "---\n",
        "\n",
        "### **4) Compute the best-fit line using scikit-learn**\n",
        "\n",
        "```python\n",
        "lin1 = linear_model.LinearRegression()\n",
        "lin1.fit(X_sample, y_sample)\n",
        "```\n",
        "\n",
        "Learns:\n",
        "\n",
        "```python\n",
        "t0 = intercept (Œ∏0)\n",
        "t1 = slope (Œ∏1)\n",
        "```\n",
        "\n",
        "Plotting:\n",
        "\n",
        "```python\n",
        "plt.plot(X, t0 + t1 * X)\n",
        "```\n",
        "\n",
        "This is the **true best-fit line**.\n",
        "\n",
        "---\n",
        "\n",
        "### **5) Predict for Cyprus**\n",
        "\n",
        "```python\n",
        "cyprus_predicted_life_satisfaction = lin1.predict([[cyprus_gdp]])[0,0]\n",
        "```\n",
        "\n",
        "Then:\n",
        "\n",
        "* Draw a vertical red dashed line\n",
        "* Mark the predicted point with a red circle\n",
        "\n",
        "---\n",
        "\n",
        "### **6) Find missing / out-of-range countries**\n",
        "\n",
        "```python\n",
        "missing_data = full_country_stats[(GDP < min) | (GDP > max)]\n",
        "```\n",
        "\n",
        "These are countries not included in the training slice.\n",
        "\n",
        "You annotate them on the plot with arrows.\n",
        "\n",
        "---\n",
        "\n",
        "### **7) Fit a linear model on full data**\n",
        "\n",
        "```python\n",
        "lin_reg_full.fit(Xfull, yfull)\n",
        "plt.plot(X, t0full + t1full * X, \"k\")\n",
        "```\n",
        "\n",
        "This produces the **correct full-dataset line**.\n",
        "\n",
        "---\n",
        "\n",
        "### **8) Polynomial regression (degree 10)**\n",
        "\n",
        "```python\n",
        "poly = PolynomialFeatures(degree=10)\n",
        "scaler = StandardScaler()\n",
        "pipeline_reg = Pipeline([...])\n",
        "```\n",
        "\n",
        "Fits a high-degree curve ‚Üí **overfits**.\n",
        "Plot shows unrealistic wiggles.\n",
        "\n",
        "---\n",
        "\n",
        "### **9) Ridge regression**\n",
        "\n",
        "```python\n",
        "ridge = linear_model.Ridge(alpha=10**9.5)\n",
        "ridge.fit(X_sample, y_sample)\n",
        "```\n",
        "\n",
        "This produces a **smoothed, very stable line** by shrinking Œ∏1.\n",
        "\n",
        "You plot:\n",
        "\n",
        "* Partial-data linear model (blue dotted)\n",
        "* Full-data model (black line)\n",
        "* Ridge model (blue dashed)\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ Want a **super-short cheat sheet version** (10 lines)?\n",
        "\n",
        "I can compress all of this into a one-page interview-ready summary.\n",
        "\n",
        "</details>"
      ],
      "metadata": {
        "id": "-Enl7W0UMTct"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b> ‚úÖAI Understanding Template-ML Landscape - CheatSheet </b></summary>\n",
        "\n",
        "Here is your **interview-style Q&A summary**, short and crisp, covering **AI: What / How / Fail / When / Mental Model / Prompting / Alternatives** + **code explanation**.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **INTERVIEW Q&A SUMMARY ‚Äî Linear Regression GDP vs Life Satisfaction**\n",
        "\n",
        "---\n",
        "\n",
        "## **1) What is this code doing?**\n",
        "\n",
        "This code demonstrates an end-to-end **linear regression workflow** on GDP-per-capita vs life-satisfaction.\n",
        "It visualizes data, draws manual lines, learns best-fit parameters, predicts values, handles missing data, shows overfitting, and uses Ridge regularization.\n",
        "\n",
        "---\n",
        "\n",
        "## **2) What is the main AI/ML concept used here?**\n",
        "\n",
        "**Simple Linear Regression**:\n",
        "[\n",
        "\\hat{y} = \\theta_0 + \\theta_1 x\n",
        "]\n",
        "It finds the best straight line to predict life satisfaction from GDP.\n",
        "\n",
        "---\n",
        "\n",
        "## **3) How does the model reason?**\n",
        "\n",
        "It calculates:\n",
        "\n",
        "* A **slope (Œ∏‚ÇÅ)** telling how life satisfaction changes with GDP\n",
        "* An **intercept (Œ∏‚ÇÄ)** defining baseline satisfaction\n",
        "* Predicts by inserting GDP (x) into the linear formula.\n",
        "\n",
        "Polynomial regression adds higher powers (x^2, x^3) to create curves.\n",
        "Ridge regression penalizes large coefficients to prevent instability.\n",
        "\n",
        "---\n",
        "\n",
        "## **4) Where does this approach fail?**\n",
        "\n",
        "It fails when:\n",
        "\n",
        "* Relationship is **non-linear**\n",
        "* Data contains **noise/outliers**\n",
        "* Important features are missing\n",
        "* Polynomial regression **overfits** small datasets\n",
        "* Missing countries distort slope/intercept\n",
        "\n",
        "---\n",
        "\n",
        "## **5) When should linear regression be used?**\n",
        "\n",
        "Use when:\n",
        "\n",
        "* The trend appears **straight-line**\n",
        "* You want **quick, interpretable** results\n",
        "* Dataset is **small/clean**\n",
        "* You're building a **baseline model**\n",
        "\n",
        "Use polynomial or Ridge when data bends or overfits.\n",
        "\n",
        "---\n",
        "\n",
        "## **6) What is the mental model behind this code?**\n",
        "\n",
        "Think of it as:\n",
        "\n",
        "> ‚ÄúDraw a straight line that best fits all the country points.‚Äù\n",
        "\n",
        "Polynomial model:\n",
        "\n",
        "> ‚ÄúA bendy line trying too hard to fit every point.‚Äù\n",
        "\n",
        "Ridge model:\n",
        "\n",
        "> ‚ÄúA stable line that avoids wild slopes.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## **7) How do you prompt or use this model?**\n",
        "\n",
        "You ‚Äúprompt‚Äù it by giving numeric input:\n",
        "\n",
        "* Train: `lin1.fit(X, y)`\n",
        "* Predict: `lin1.predict([[GDP]])`\n",
        "* Plot: give X grid ‚Üí `plt.plot(X, t0 + t1*X)`\n",
        "\n",
        "For polynomial prompting:\n",
        "Use `Pipeline([poly ‚Üí scaler ‚Üí linear])`.\n",
        "\n",
        "---\n",
        "\n",
        "## **8) What are alternatives to this model?**\n",
        "\n",
        "| Model                 | Use case                |\n",
        "| --------------------- | ----------------------- |\n",
        "| Polynomial Regression | Non-linear curves       |\n",
        "| Ridge/Lasso           | Regularization needed   |\n",
        "| Random Forest         | Robust tabular learning |\n",
        "| Gradient Boosting     | High predictive power   |\n",
        "| Neural Network        | Complex relationships   |\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **CODE SECTIONS ‚Äî Interview-Style Explanation**\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: What does the highlighting code do?**\n",
        "\n",
        "```python\n",
        "highlighted_countries = country_stats.loc[list(position_text.keys())]\n",
        "```\n",
        "\n",
        "**A:** Selects specific countries and sorts them by GDP.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: What is the scatter plot used for?**\n",
        "\n",
        "```python\n",
        "country_stats.plot(kind='scatter', x=gdppc_col, y=lifesat_col)\n",
        "```\n",
        "\n",
        "Shows correlation between GDP and life satisfaction.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: Why plot manual lines (Œ∏‚ÇÄ, Œ∏‚ÇÅ)?**\n",
        "\n",
        "To visually compare different slopes/intercepts and understand how linear models behave.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: How is the real regression model trained?**\n",
        "\n",
        "```python\n",
        "lin1 = LinearRegression()\n",
        "lin1.fit(X_sample, y_sample)\n",
        "```\n",
        "\n",
        "Learns best Œ∏‚ÇÄ and Œ∏‚ÇÅ from data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: How is prediction done for Cyprus?**\n",
        "\n",
        "```python\n",
        "lin1.predict([[cyprus_gdp]])\n",
        "```\n",
        "\n",
        "Feeds GDP into the model ‚Üí outputs life satisfaction.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: How does the code handle missing or out-of-range countries?**\n",
        "\n",
        "It filters countries outside the training GDP range and annotates them separately.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: What does polynomial regression demonstrate?**\n",
        "\n",
        "```python\n",
        "PolynomialFeatures(degree=10)\n",
        "```\n",
        "\n",
        "It creates an overly flexible curve ‚Üí shows **overfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: Why use Ridge Regression?**\n",
        "\n",
        "```python\n",
        "ridge = Ridge(alpha=10**9.5)\n",
        "```\n",
        "\n",
        "Adds a penalty to Œ∏‚ÇÅ to reduce overfitting and stabilize the model.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê **Want a 1-page cheat sheet, diagram, or 20 rapid-fire interview questions based on this code?**\n",
        "\n",
        "\n",
        "<details>"
      ],
      "metadata": {
        "id": "Ki9anlQFOH3v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b> ‚úÖAI Understanding Template- interview-style Q&A style summary </b></summary>\n",
        "Here is your **interview-style Q&A summary**, short and crisp, covering **AI: What / How / Fail / When / Mental Model / Prompting / Alternatives** + **code explanation**.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **INTERVIEW Q&A SUMMARY ‚Äî Linear Regression GDP vs Life Satisfaction**\n",
        "\n",
        "---\n",
        "\n",
        "## **1) What is this code doing?**\n",
        "\n",
        "This code demonstrates an end-to-end **linear regression workflow** on GDP-per-capita vs life-satisfaction.\n",
        "It visualizes data, draws manual lines, learns best-fit parameters, predicts values, handles missing data, shows overfitting, and uses Ridge regularization.\n",
        "\n",
        "---\n",
        "\n",
        "## **2) What is the main AI/ML concept used here?**\n",
        "\n",
        "**Simple Linear Regression**:\n",
        "[\n",
        "\\hat{y} = \\theta_0 + \\theta_1 x\n",
        "]\n",
        "It finds the best straight line to predict life satisfaction from GDP.\n",
        "\n",
        "---\n",
        "\n",
        "## **3) How does the model reason?**\n",
        "\n",
        "It calculates:\n",
        "\n",
        "* A **slope (Œ∏‚ÇÅ)** telling how life satisfaction changes with GDP\n",
        "* An **intercept (Œ∏‚ÇÄ)** defining baseline satisfaction\n",
        "* Predicts by inserting GDP (x) into the linear formula.\n",
        "\n",
        "Polynomial regression adds higher powers (x^2, x^3) to create curves.\n",
        "Ridge regression penalizes large coefficients to prevent instability.\n",
        "\n",
        "---\n",
        "\n",
        "## **4) Where does this approach fail?**\n",
        "\n",
        "It fails when:\n",
        "\n",
        "* Relationship is **non-linear**\n",
        "* Data contains **noise/outliers**\n",
        "* Important features are missing\n",
        "* Polynomial regression **overfits** small datasets\n",
        "* Missing countries distort slope/intercept\n",
        "\n",
        "---\n",
        "\n",
        "## **5) When should linear regression be used?**\n",
        "\n",
        "Use when:\n",
        "\n",
        "* The trend appears **straight-line**\n",
        "* You want **quick, interpretable** results\n",
        "* Dataset is **small/clean**\n",
        "* You're building a **baseline model**\n",
        "\n",
        "Use polynomial or Ridge when data bends or overfits.\n",
        "\n",
        "---\n",
        "\n",
        "## **6) What is the mental model behind this code?**\n",
        "\n",
        "Think of it as:\n",
        "\n",
        "> ‚ÄúDraw a straight line that best fits all the country points.‚Äù\n",
        "\n",
        "Polynomial model:\n",
        "\n",
        "> ‚ÄúA bendy line trying too hard to fit every point.‚Äù\n",
        "\n",
        "Ridge model:\n",
        "\n",
        "> ‚ÄúA stable line that avoids wild slopes.‚Äù\n",
        "\n",
        "---\n",
        "\n",
        "## **7) How do you prompt or use this model?**\n",
        "\n",
        "You ‚Äúprompt‚Äù it by giving numeric input:\n",
        "\n",
        "* Train: `lin1.fit(X, y)`\n",
        "* Predict: `lin1.predict([[GDP]])`\n",
        "* Plot: give X grid ‚Üí `plt.plot(X, t0 + t1*X)`\n",
        "\n",
        "For polynomial prompting:\n",
        "Use `Pipeline([poly ‚Üí scaler ‚Üí linear])`.\n",
        "\n",
        "---\n",
        "\n",
        "## **8) What are alternatives to this model?**\n",
        "\n",
        "| Model                 | Use case                |\n",
        "| --------------------- | ----------------------- |\n",
        "| Polynomial Regression | Non-linear curves       |\n",
        "| Ridge/Lasso           | Regularization needed   |\n",
        "| Random Forest         | Robust tabular learning |\n",
        "| Gradient Boosting     | High predictive power   |\n",
        "| Neural Network        | Complex relationships   |\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **CODE SECTIONS ‚Äî Interview-Style Explanation**\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: What does the highlighting code do?**\n",
        "\n",
        "```python\n",
        "highlighted_countries = country_stats.loc[list(position_text.keys())]\n",
        "```\n",
        "\n",
        "**A:** Selects specific countries and sorts them by GDP.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: What is the scatter plot used for?**\n",
        "\n",
        "```python\n",
        "country_stats.plot(kind='scatter', x=gdppc_col, y=lifesat_col)\n",
        "```\n",
        "\n",
        "Shows correlation between GDP and life satisfaction.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: Why plot manual lines (Œ∏‚ÇÄ, Œ∏‚ÇÅ)?**\n",
        "\n",
        "To visually compare different slopes/intercepts and understand how linear models behave.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: How is the real regression model trained?**\n",
        "\n",
        "```python\n",
        "lin1 = LinearRegression()\n",
        "lin1.fit(X_sample, y_sample)\n",
        "```\n",
        "\n",
        "Learns best Œ∏‚ÇÄ and Œ∏‚ÇÅ from data.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: How is prediction done for Cyprus?**\n",
        "\n",
        "```python\n",
        "lin1.predict([[cyprus_gdp]])\n",
        "```\n",
        "\n",
        "Feeds GDP into the model ‚Üí outputs life satisfaction.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: How does the code handle missing or out-of-range countries?**\n",
        "\n",
        "It filters countries outside the training GDP range and annotates them separately.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: What does polynomial regression demonstrate?**\n",
        "\n",
        "```python\n",
        "PolynomialFeatures(degree=10)\n",
        "```\n",
        "\n",
        "It creates an overly flexible curve ‚Üí shows **overfitting**.\n",
        "\n",
        "---\n",
        "\n",
        "### **Q: Why use Ridge Regression?**\n",
        "\n",
        "```python\n",
        "ridge = Ridge(alpha=10**9.5)\n",
        "```\n",
        "\n",
        "Adds a penalty to Œ∏‚ÇÅ to reduce overfitting and stabilize the model.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚≠ê **Want a 1-page cheat sheet, diagram, or 20 rapid-fire interview questions based on this code?**\n",
        "\n",
        "\n",
        "<details>"
      ],
      "metadata": {
        "id": "t5ZHtrK-PNlh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<details>\n",
        "<summary><b> ‚úÖAI Understanding Template-ML Landscape - 20 Quick fire interview questions </b></summary>\n",
        "\n",
        "Here is your **1-page cheat sheet + diagram + 20 rapid-fire interview Qs** ‚Äî all short, crisp, and interview-ready.\n",
        "\n",
        "---\n",
        "\n",
        "# ‚úÖ **1-PAGE CHEAT SHEET ‚Äî GDP vs Life Satisfaction (Linear Regression)**\n",
        "\n",
        "## **1) Core Idea**\n",
        "\n",
        "Fit a line:\n",
        "[\n",
        "\\hat{y} = \\theta_0 + \\theta_1 x\n",
        "]\n",
        "Predict life satisfaction (y) using GDP per capita (x).\n",
        "\n",
        "---\n",
        "\n",
        "## **2) Workflow Summary**\n",
        "\n",
        "1. **Load/clean country stats**\n",
        "2. **Scatter plot** (see correlation)\n",
        "3. **Try manual Œ∏‚ÇÄ, Œ∏‚ÇÅ lines** (intuition)\n",
        "4. **Fit Linear Regression**\n",
        "5. **Predict for a country (e.g., Cyprus)**\n",
        "6. **Visualize prediction**\n",
        "7. **Identify missing/out-of-range countries**\n",
        "8. **Polynomial Regression ‚Üí Overfitting**\n",
        "9. **Ridge Regression ‚Üí Regularization**\n",
        "10. **Compare partial vs full dataset models**\n",
        "\n",
        "---\n",
        "\n",
        "## **3) Important Concepts**\n",
        "\n",
        "* **Linear Regression:** Finds best straight line\n",
        "* **Intercept (Œ∏‚ÇÄ):** Life satisfaction at zero GDP\n",
        "* **Slope (Œ∏‚ÇÅ):** Change in satisfaction for change in GDP\n",
        "* **Polynomial Features:** Adds x¬≤, x¬≥‚Ä¶ ‚Üí flexible curve\n",
        "* **Overfitting:** Curve models noise instead of trend\n",
        "* **Regularization (Ridge):** Penalizes large weights ‚Üí stable model\n",
        "* **Pipeline:** Sequential transformation + model\n",
        "\n",
        "---\n",
        "\n",
        "## **4) Key Code Blocks**\n",
        "\n",
        "### **Fit Model**\n",
        "\n",
        "```python\n",
        "lin1 = LinearRegression()\n",
        "lin1.fit(X, y)\n",
        "```\n",
        "\n",
        "### **Predict**\n",
        "\n",
        "```python\n",
        "lin1.predict([[gdp]])\n",
        "```\n",
        "\n",
        "### **Polynomial + Scaling + Regression**\n",
        "\n",
        "```python\n",
        "Pipeline([\n",
        " ('poly', PolynomialFeatures(10)),\n",
        " ('scal', StandardScaler()),\n",
        " ('lin', LinearRegression())\n",
        "])\n",
        "```\n",
        "\n",
        "### **Ridge**\n",
        "\n",
        "```python\n",
        "Ridge(alpha=1e9)\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## **5) When to Use What?**\n",
        "\n",
        "| Situation                     | Use                   |\n",
        "| ----------------------------- | --------------------- |\n",
        "| Trend looks linear            | Linear Regression     |\n",
        "| Non-linear but smooth         | Polynomial Regression |\n",
        "| Overfitting risk              | Ridge/Lasso           |\n",
        "| Complex + noisy               | Random Forest         |\n",
        "| High accuracy on tabular data | Gradient Boosting     |\n",
        "\n",
        "---\n",
        "\n",
        "## **6) Mental Model**\n",
        "\n",
        "* Linear: **Straight ruler** fitting trend\n",
        "* Polynomial: **Flexible wire** fitting every bump\n",
        "* Ridge: **Ruler with weight** preventing wobbling\n",
        "\n",
        "---\n",
        "\n",
        "# üéØ **Diagram ‚Äì Simple Visual Model**\n",
        "\n",
        "```\n",
        "Scatter plot: GDP (x) ‚Üí Life Satisfaction (y)\n",
        "\n",
        "                 ‚óè\n",
        "    ‚óè     ‚óè   ‚óè        ‚óè\n",
        " ‚óè         ‚óè  ‚óè  ‚óè   \n",
        "---------------------------- x (GDP)\n",
        "       Best-Fit Line ‚Üí\n",
        "```\n",
        "\n",
        "Polynomial Regression:\n",
        "\n",
        "```\n",
        "A very curvy line trying too hard to fit every point\n",
        "```\n",
        "\n",
        "Ridge Regression:\n",
        "\n",
        "```\n",
        "Straighter, more stable line\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "# üî• **20 Rapid-Fire Interview Questions (and short answers)**\n",
        "\n",
        "### **1. What algorithm is used here?**\n",
        "\n",
        "Linear Regression.\n",
        "\n",
        "### **2. What is Œ∏‚ÇÄ?**\n",
        "\n",
        "Intercept.\n",
        "\n",
        "### **3. What is Œ∏‚ÇÅ?**\n",
        "\n",
        "Slope/coefficient.\n",
        "\n",
        "### **4. What does slope represent?**\n",
        "\n",
        "How much life satisfaction changes per GDP unit.\n",
        "\n",
        "### **5. What library performs regression?**\n",
        "\n",
        "`sklearn.linear_model`.\n",
        "\n",
        "### **6. Why plot manual lines?**\n",
        "\n",
        "To visualize how Œ∏‚ÇÄ, Œ∏‚ÇÅ affect predictions.\n",
        "\n",
        "### **7. How do you predict for Cyprus?**\n",
        "\n",
        "Use `model.predict([[GDP]])`.\n",
        "\n",
        "### **8. What is overfitting?**\n",
        "\n",
        "Model learns noise instead of pattern.\n",
        "\n",
        "### **9. How do polynomial features cause overfitting?**\n",
        "\n",
        "Too many curve terms.\n",
        "\n",
        "### **10. What does Ridge do?**\n",
        "\n",
        "Penalizes large weights ‚Üí reduces overfitting.\n",
        "\n",
        "### **11. What is a pipeline?**\n",
        "\n",
        "Chain of transformations + model.\n",
        "\n",
        "### **12. Why scale polynomial features?**\n",
        "\n",
        "Large values distort regression.\n",
        "\n",
        "### **13. What happens if GDP range is too small?**\n",
        "\n",
        "Model becomes unstable; wrong slope.\n",
        "\n",
        "### **14. Why annotate missing countries?**\n",
        "\n",
        "To show they were excluded and distort results.\n",
        "\n",
        "### **15. What is the input feature?**\n",
        "\n",
        "GDP per capita.\n",
        "\n",
        "### **16. What is the target?**\n",
        "\n",
        "Life satisfaction index.\n",
        "\n",
        "### **17. Why use np.linspace?**\n",
        "\n",
        "Create smooth X-grid for plotting predictions.\n",
        "\n",
        "### **18. What is `coef_`?**\n",
        "\n",
        "Learned slope values.\n",
        "\n",
        "### **19. What is `intercept_`?**\n",
        "\n",
        "Learned bias/constant.\n",
        "\n",
        "### **20. Why use a scatter plot first?**\n",
        "\n",
        "Check if linear model makes sense.\n",
        "\n",
        "---\n",
        "\n",
        "If you want, I can also prepare:\n",
        "\n",
        "‚úî **HR-style summary**\n",
        "‚úî **Technical deep-dive version**\n",
        "‚úî **End-to-end interview notes (prep sheet)**\n",
        "\n",
        "Just tell me which one.\n",
        "\n",
        "\n",
        "<details>"
      ],
      "metadata": {
        "id": "1qlmZ35vPt9C"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wVPdX4CI1m_"
      },
      "source": [
        "# Exercise Solutions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-2jbyHRI1m_"
      },
      "source": [
        "1. Machine Learning is about building systems that can learn from data. Learning means getting better at some task, given some performance measure.\n",
        "2. Machine Learning is great for complex problems for which we have no algorithmic solution, to replace long lists of hand-tuned rules, to build systems that adapt to fluctuating environments, and finally to help humans learn (e.g., data mining).\n",
        "3. A labeled training set is a training set that contains the desired solution (a.k.a. a label) for each instance.\n",
        "4. The two most common supervised tasks are regression and classification.\n",
        "5. Common unsupervised tasks include clustering, visualization, dimensionality reduction, and association rule learning.\n",
        "6. Reinforcement Learning is likely to perform best if we want a robot to learn to walk in various unknown terrains, since this is typically the type of problem that Reinforcement Learning tackles. It might be possible to express the problem as a supervised or semi-supervised learning problem, but it would be less natural.\n",
        "7. If you don't know how to define the groups, then you can use a clustering algorithm (unsupervised learning) to segment your customers into clusters of similar customers. However, if you know what groups you would like to have, then you can feed many examples of each group to a classification algorithm (supervised learning), and it will classify all your customers into these groups.\n",
        "8. Spam detection is a typical supervised learning problem: the algorithm is fed many emails along with their labels (spam or not spam).\n",
        "9. An online learning system can learn incrementally, as opposed to a batch learning system. This makes it capable of adapting rapidly to both changing data and autonomous systems, and of training on very large quantities of data.\n",
        "10. Out-of-core algorithms can handle vast quantities of data that cannot fit in a computer's main memory. An out-of-core learning algorithm chops the data into mini-batches and uses online learning techniques to learn from these mini-batches.\n",
        "11. An instance-based learning system learns the training data by heart; then, when given a new instance, it uses a similarity measure to find the most similar learned instances and uses them to make predictions.\n",
        "12. A model has one or more model parameters that determine what it will predict given a new instance (e.g., the slope of a linear model). A learning algorithm tries to find optimal values for these parameters such that the model generalizes well to new instances. A hyperparameter is a parameter of the learning algorithm itself, not of the model (e.g., the amount of regularization to apply).\n",
        "13. Model-based learning algorithms search for an optimal value for the model parameters such that the model will generalize well to new instances. We usually train such systems by minimizing a cost function that measures how bad the system is at making predictions on the training data, plus a penalty for model complexity if the model is regularized. To make predictions, we feed the new instance's features into the model's prediction function, using the parameter values found by the learning algorithm.\n",
        "14. Some of the main challenges in Machine Learning are the lack of data, poor data quality, nonrepresentative data, uninformative features, excessively simple models that underfit the training data, and excessively complex models that overfit the data.\n",
        "15. If a model performs great on the training data but generalizes poorly to new instances, the model is likely overfitting the training data (or we got extremely lucky on the training data). Possible solutions to overfitting are getting more data, simplifying the model (selecting a simpler algorithm, reducing the number of parameters or features used, or regularizing the model), or reducing the noise in the training data.\n",
        "16. A test set is used to estimate the generalization error that a model will make on new instances, before the model is launched in production.\n",
        "17. A validation set is used to compare models. It makes it possible to select the best model and tune the hyperparameters.\n",
        "18. The train-dev set is used when there is a risk of mismatch between the training data and the data used in the validation and test datasets (which should always be as close as possible to the data used once the model is in production). The train-dev set is a part of the training set that's held out (the model is not trained on it). The model is trained on the rest of the training set, and evaluated on both the train-dev set and the validation set. If the model performs well on the training set but not on the train-dev set, then the model is likely overfitting the training set. If it performs well on both the training set and the train-dev set, but not on the validation set, then there is probably a significant data mismatch between the training data and the validation + test data, and you should try to improve the training data to make it look more like the validation + test data.\n",
        "19. If you tune hyperparameters using the test set, you risk overfitting the test set, and the generalization error you measure will be optimistic (you may launch a model that performs worse than you expect)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SyVWap6AI1m_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "metadata": {
      "interpreter": {
        "hash": "22b0ec00cd9e253c751e6d2619fc0bb2d18ed12980de3246690d5be49479dd65"
      }
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": true
    },
    "toc_position": {
      "height": "616px",
      "left": "0px",
      "right": "20px",
      "top": "106px",
      "width": "213px"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}